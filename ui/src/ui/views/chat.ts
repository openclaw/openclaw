import { html, nothing } from "lit";
import { ref } from "lit/directives/ref.js";
import { repeat } from "lit/directives/repeat.js";
import type { SessionsListResult } from "../types.ts";
import type { ChatItem, MessageGroup } from "../types/chat-types.ts";
import type { ChatAttachment, ChatQueueItem } from "../ui-types.ts";
import {
  renderMessageGroup,
  renderReadingIndicatorGroup,
  renderStreamingGroup,
} from "../chat/grouped-render.ts";
import { normalizeMessage, normalizeRoleForGrouping } from "../chat/message-normalizer.ts";
import { icons } from "../icons.ts";
import { renderMarkdownSidebar } from "./markdown-sidebar.ts";
import "../components/resizable-divider.ts";

export type CompactionIndicatorStatus = {
  active: boolean;
  startedAt: number | null;
  completedAt: number | null;
};

export type ChatProps = {
  sessionKey: string;
  onSessionKeyChange: (next: string) => void;
  thinkingLevel: string | null;
  showThinking: boolean;
  loading: boolean;
  sending: boolean;
  canAbort?: boolean;
  compactionStatus?: CompactionIndicatorStatus | null;
  messages: unknown[];
  toolMessages: unknown[];
  stream: string | null;
  streamStartedAt: number | null;
  assistantAvatarUrl?: string | null;
  draft: string;
  queue: ChatQueueItem[];
  connected: boolean;
  canSend: boolean;
  disabledReason: string | null;
  error: string | null;
  sessions: SessionsListResult | null;
  // Focus mode
  focusMode: boolean;
  // Sidebar state
  sidebarOpen?: boolean;
  sidebarContent?: string | null;
  sidebarError?: string | null;
  splitRatio?: number;
  assistantName: string;
  assistantAvatar: string | null;
  // Image attachments
  attachments?: ChatAttachment[];
  onAttachmentsChange?: (attachments: ChatAttachment[]) => void;
  // Scroll control
  showNewMessages?: boolean;
  onScrollToBottom?: () => void;
  // Event handlers
  onRefresh: () => void;
  onToggleFocusMode: () => void;
  onDraftChange: (next: string) => void;
  onSend: () => void;
  onAbort?: () => void;
  onQueueRemove: (id: string) => void;
  onNewSession: () => void;
  onOpenSidebar?: (content: string) => void;
  onCloseSidebar?: () => void;
  onSplitRatioChange?: (ratio: number) => void;
  onChatScroll?: (event: Event) => void;
};

// --- Voice input (Web Speech API) ---

const SpeechRecognitionCtor: typeof SpeechRecognition | undefined =
  (globalThis as any).SpeechRecognition ?? (globalThis as any).webkitSpeechRecognition;

type VoiceState = {
  listening: boolean;
  recognition: SpeechRecognition | null;
  interim: string;
  accumulated: string; // all finalized text so far in this session
  ttsEnabled: boolean; // auto-speak assistant replies (persists until user toggles off)
  speaking: boolean; // currently speaking
};
const voiceState: VoiceState = {
  listening: false,
  recognition: null,
  interim: "",
  accumulated: "",
  ttsEnabled: false,
  speaking: false,
};

// --- Browser TTS for voice replies ---
let ttsRerender: (() => void) | null = null;
let preferredVoice: SpeechSynthesisVoice | null = null;

// Pick the best available voice — prefer natural/premium voices
function selectBestVoice(): SpeechSynthesisVoice | null {
  if (!("speechSynthesis" in globalThis)) {
    return null;
  }
  const voices = speechSynthesis.getVoices();
  if (voices.length === 0) {
    return null;
  }

  // Ranked preferences: natural-sounding English voices
  const preferred = [
    // macOS premium voices
    "Samantha (Enhanced)",
    "Samantha",
    "Karen (Enhanced)",
    "Karen",
    "Daniel (Enhanced)",
    "Daniel",
    // Google voices (Chrome)
    "Google UK English Female",
    "Google UK English Male",
    "Google US English",
    // Microsoft voices (Edge/Windows)
    "Microsoft Zira",
    "Microsoft David",
  ];

  for (const name of preferred) {
    const match = voices.find((v) => v.name.includes(name));
    if (match) {
      return match;
    }
  }

  // Fallback: any English voice that's not "Google 日本語" etc.
  const englishVoice = voices.find((v) => v.lang.startsWith("en") && !v.name.includes("Google 日"));
  return englishVoice ?? voices[0];
}

// Voices load async in some browsers
if ("speechSynthesis" in globalThis) {
  speechSynthesis.addEventListener("voiceschanged", () => {
    preferredVoice = selectBestVoice();
  });
  preferredVoice = selectBestVoice();
}

function cleanTextForSpeech(text: string): string {
  return text
    .replace(/MEDIA:\S+/g, "")
    .replace(/```[\s\S]*?```/g, " code block ")
    .replace(/`([^`]+)`/g, "$1")
    .replace(/\*\*([^*]+)\*\*/g, "$1")
    .replace(/\*([^*]+)\*/g, "$1")
    .replace(/#{1,6}\s*/g, "")
    .replace(/\[([^\]]+)\]\([^)]+\)/g, "$1")
    .replace(/[<>]/g, "")
    .replace(/https?:\/\/\S+/g, "")
    .replace(/\p{Emoji_Presentation}/gu, "")
    .replace(/\p{Extended_Pictographic}/gu, "")
    .replace(/\n{2,}/g, ". ")
    .replace(/\s{2,}/g, " ")
    .trim();
}

function speakText(text: string) {
  if (!("speechSynthesis" in globalThis) || !voiceState.ttsEnabled) {
    return;
  }
  const clean = cleanTextForSpeech(text);
  if (!clean) {
    return;
  }
  const utterance = new SpeechSynthesisUtterance(clean);
  if (preferredVoice) {
    utterance.voice = preferredVoice;
  }
  utterance.rate = 1.05;
  utterance.pitch = 1.0;
  utterance.onstart = () => {
    voiceState.speaking = true;
    ttsRerender?.();
  };
  utterance.onend = () => {
    voiceState.speaking = false;
    ttsRerender?.();
  };
  utterance.onerror = () => {
    voiceState.speaking = false;
    ttsRerender?.();
  };
  speechSynthesis.cancel();
  speechSynthesis.speak(utterance);
}

function stopSpeaking() {
  if ("speechSynthesis" in globalThis) {
    speechSynthesis.cancel();
  }
  voiceState.speaking = false;
}

function stopVoiceRecognition() {
  if (voiceState.recognition) {
    voiceState.recognition.onend = null;
    voiceState.recognition.stop();
    voiceState.recognition = null;
  }
  voiceState.listening = false;
  voiceState.interim = "";
}

function startVoiceRecognition(props: ChatProps, rerender: () => void) {
  if (!SpeechRecognitionCtor) {
    return;
  }
  stopVoiceRecognition();

  // Start fresh: capture what's already in the draft, accumulate on top
  voiceState.accumulated = props.draft;

  const recognition = new SpeechRecognitionCtor();
  recognition.continuous = true;
  recognition.interimResults = true;
  recognition.lang = "en-US";

  recognition.onresult = (event: SpeechRecognitionEvent) => {
    let finalTranscript = "";
    let interimTranscript = "";
    for (let i = event.resultIndex; i < event.results.length; i++) {
      const result = event.results[i];
      if (result.isFinal) {
        finalTranscript += result[0].transcript;
      } else {
        interimTranscript += result[0].transcript;
      }
    }
    if (finalTranscript) {
      const spacer = voiceState.accumulated && !voiceState.accumulated.endsWith(" ") ? " " : "";
      voiceState.accumulated += spacer + finalTranscript;
      props.onDraftChange(voiceState.accumulated);
      voiceState.interim = "";
    } else {
      voiceState.interim = interimTranscript;
    }
    rerender();
  };

  recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
    if (event.error === "aborted" || event.error === "no-speech") {
      return;
    }
    console.error("Speech recognition error:", event.error);
    stopVoiceRecognition();
    rerender();
  };

  recognition.onend = () => {
    if (voiceState.listening && voiceState.recognition === recognition) {
      try {
        recognition.start();
      } catch {
        stopVoiceRecognition();
        rerender();
      }
    }
  };

  voiceState.recognition = recognition;
  voiceState.listening = true;
  recognition.start();
  rerender();
}

function toggleVoiceRecognition(props: ChatProps, rerender: () => void) {
  if (voiceState.listening) {
    // 2nd click: stop listening, enable TTS, auto-send
    const textToSend = voiceState.accumulated.trim();
    stopVoiceRecognition();
    voiceState.ttsEnabled = true;
    if (textToSend) {
      // Ensure draft is set then send (onSend reads draft and clears it)
      props.onDraftChange(textToSend);
      // Use microtask so Lit updates draft before onSend reads it
      queueMicrotask(() => props.onSend());
    }
    voiceState.accumulated = "";
    rerender();
  } else {
    startVoiceRecognition(props, rerender);
  }
}

function toggleTts(rerender: () => void) {
  if (voiceState.ttsEnabled) {
    voiceState.ttsEnabled = false;
    stopSpeaking();
  } else {
    voiceState.ttsEnabled = true;
  }
  rerender();
}

const COMPACTION_TOAST_DURATION_MS = 5000;

function adjustTextareaHeight(el: HTMLTextAreaElement) {
  el.style.height = "auto";
  el.style.height = `${el.scrollHeight}px`;
}

function renderCompactionIndicator(status: CompactionIndicatorStatus | null | undefined) {
  if (!status) {
    return nothing;
  }

  // Show "compacting..." while active
  if (status.active) {
    return html`
      <div class="callout info compaction-indicator compaction-indicator--active">
        ${icons.loader} Compacting context...
      </div>
    `;
  }

  // Show "compaction complete" briefly after completion
  if (status.completedAt) {
    const elapsed = Date.now() - status.completedAt;
    if (elapsed < COMPACTION_TOAST_DURATION_MS) {
      return html`
        <div class="callout success compaction-indicator compaction-indicator--complete">
          ${icons.check} Context compacted
        </div>
      `;
    }
  }

  return nothing;
}

function generateAttachmentId(): string {
  return `att-${Date.now()}-${Math.random().toString(36).slice(2, 9)}`;
}

function handlePaste(e: ClipboardEvent, props: ChatProps) {
  const items = e.clipboardData?.items;
  if (!items || !props.onAttachmentsChange) {
    return;
  }

  const imageItems: DataTransferItem[] = [];
  for (let i = 0; i < items.length; i++) {
    const item = items[i];
    if (item.type.startsWith("image/")) {
      imageItems.push(item);
    }
  }

  if (imageItems.length === 0) {
    return;
  }

  e.preventDefault();

  for (const item of imageItems) {
    const file = item.getAsFile();
    if (!file) {
      continue;
    }

    const reader = new FileReader();
    reader.addEventListener("load", () => {
      const dataUrl = reader.result as string;
      const newAttachment: ChatAttachment = {
        id: generateAttachmentId(),
        dataUrl,
        mimeType: file.type,
      };
      const current = props.attachments ?? [];
      props.onAttachmentsChange?.([...current, newAttachment]);
    });
    reader.readAsDataURL(file);
  }
}

function renderAttachmentPreview(props: ChatProps) {
  const attachments = props.attachments ?? [];
  if (attachments.length === 0) {
    return nothing;
  }

  return html`
    <div class="chat-attachments">
      ${attachments.map(
        (att) => html`
          <div class="chat-attachment">
            <img
              src=${att.dataUrl}
              alt="Attachment preview"
              class="chat-attachment__img"
            />
            <button
              class="chat-attachment__remove"
              type="button"
              aria-label="Remove attachment"
              @click=${() => {
                const next = (props.attachments ?? []).filter((a) => a.id !== att.id);
                props.onAttachmentsChange?.(next);
              }}
            >
              ${icons.x}
            </button>
          </div>
        `,
      )}
    </div>
  `;
}

// Track message count so we can detect new assistant messages for TTS
let prevMessageCount = 0;
let prevStreamText: string | null = null;

export function renderChat(props: ChatProps, rerender?: () => void) {
  const canCompose = props.connected;
  const isBusy = props.sending || props.stream !== null;
  const canAbort = Boolean(props.canAbort && props.onAbort);
  const activeSession = props.sessions?.sessions?.find((row) => row.key === props.sessionKey);
  const reasoningLevel = activeSession?.reasoningLevel ?? "off";
  const showReasoning = props.showThinking && reasoningLevel !== "off";
  const assistantIdentity = {
    name: props.assistantName,
    avatar: props.assistantAvatar ?? props.assistantAvatarUrl ?? null,
  };

  // Keep rerender ref for TTS callbacks
  if (rerender) {
    ttsRerender = rerender;
  }

  // Speak new assistant replies when TTS is enabled
  const msgCount = props.messages.length;
  if (voiceState.ttsEnabled && msgCount > prevMessageCount && msgCount > 0) {
    const last = props.messages[msgCount - 1] as Record<string, unknown>;
    const role = typeof last.role === "string" ? last.role.toLowerCase() : "";
    if (role === "assistant") {
      const content = typeof last.content === "string" ? last.content : "";
      if (content) {
        speakText(content);
      }
    }
  }
  prevMessageCount = msgCount;

  // Also speak when a stream finishes (stream goes from text → null)
  if (voiceState.ttsEnabled && prevStreamText && props.stream === null) {
    speakText(prevStreamText);
  }
  prevStreamText = props.stream;

  const hasAttachments = (props.attachments?.length ?? 0) > 0;
  const composePlaceholder = props.connected
    ? hasAttachments
      ? "Add a message or paste more images..."
      : "Message (↩ to send, Shift+↩ for line breaks, paste images)"
    : "Connect to the gateway to start chatting…";

  const splitRatio = props.splitRatio ?? 0.6;
  const sidebarOpen = Boolean(props.sidebarOpen && props.onCloseSidebar);
  const thread = html`
    <div
      class="chat-thread"
      role="log"
      aria-live="polite"
      @scroll=${props.onChatScroll}
    >
      ${
        props.loading
          ? html`
              <div class="muted">Loading chat…</div>
            `
          : nothing
      }
      ${repeat(
        buildChatItems(props),
        (item) => item.key,
        (item) => {
          if (item.kind === "reading-indicator") {
            return renderReadingIndicatorGroup(assistantIdentity);
          }

          if (item.kind === "stream") {
            return renderStreamingGroup(
              item.text,
              item.startedAt,
              props.onOpenSidebar,
              assistantIdentity,
            );
          }

          if (item.kind === "group") {
            return renderMessageGroup(item, {
              onOpenSidebar: props.onOpenSidebar,
              showReasoning,
              assistantName: props.assistantName,
              assistantAvatar: assistantIdentity.avatar,
            });
          }

          return nothing;
        },
      )}
    </div>
  `;

  return html`
    <section class="card chat">
      ${props.disabledReason ? html`<div class="callout">${props.disabledReason}</div>` : nothing}

      ${props.error ? html`<div class="callout danger">${props.error}</div>` : nothing}

      ${renderCompactionIndicator(props.compactionStatus)}

      ${
        props.focusMode
          ? html`
            <button
              class="chat-focus-exit"
              type="button"
              @click=${props.onToggleFocusMode}
              aria-label="Exit focus mode"
              title="Exit focus mode"
            >
              ${icons.x}
            </button>
          `
          : nothing
      }

      <div
        class="chat-split-container ${sidebarOpen ? "chat-split-container--open" : ""}"
      >
        <div
          class="chat-main"
          style="flex: ${sidebarOpen ? `0 0 ${splitRatio * 100}%` : "1 1 100%"}"
        >
          ${thread}
        </div>

        ${
          sidebarOpen
            ? html`
              <resizable-divider
                .splitRatio=${splitRatio}
                @resize=${(e: CustomEvent) => props.onSplitRatioChange?.(e.detail.splitRatio)}
              ></resizable-divider>
              <div class="chat-sidebar">
                ${renderMarkdownSidebar({
                  content: props.sidebarContent ?? null,
                  error: props.sidebarError ?? null,
                  onClose: props.onCloseSidebar!,
                  onViewRawText: () => {
                    if (!props.sidebarContent || !props.onOpenSidebar) {
                      return;
                    }
                    props.onOpenSidebar(`\`\`\`\n${props.sidebarContent}\n\`\`\``);
                  },
                })}
              </div>
            `
            : nothing
        }
      </div>

      ${
        props.queue.length
          ? html`
            <div class="chat-queue" role="status" aria-live="polite">
              <div class="chat-queue__title">Queued (${props.queue.length})</div>
              <div class="chat-queue__list">
                ${props.queue.map(
                  (item) => html`
                    <div class="chat-queue__item">
                      <div class="chat-queue__text">
                        ${
                          item.text ||
                          (item.attachments?.length ? `Image (${item.attachments.length})` : "")
                        }
                      </div>
                      <button
                        class="btn chat-queue__remove"
                        type="button"
                        aria-label="Remove queued message"
                        @click=${() => props.onQueueRemove(item.id)}
                      >
                        ${icons.x}
                      </button>
                    </div>
                  `,
                )}
              </div>
            </div>
          `
          : nothing
      }

      ${
        props.showNewMessages
          ? html`
            <button
              class="btn chat-new-messages"
              type="button"
              @click=${props.onScrollToBottom}
            >
              New messages ${icons.arrowDown}
            </button>
          `
          : nothing
      }

      <div class="chat-compose">
        ${renderAttachmentPreview(props)}
        ${
          voiceState.interim
            ? html`<div class="chat-voice-interim">${voiceState.interim}</div>`
            : nothing
        }
        <div class="chat-compose__row">
          <label class="field chat-compose__field">
            <span>Message</span>
            <textarea
              ${ref((el) => el && adjustTextareaHeight(el as HTMLTextAreaElement))}
              .value=${props.draft}
              ?disabled=${!props.connected}
              @keydown=${(e: KeyboardEvent) => {
                if (e.key !== "Enter") {
                  return;
                }
                if (e.isComposing || e.keyCode === 229) {
                  return;
                }
                if (e.shiftKey) {
                  return;
                } // Allow Shift+Enter for line breaks
                if (!props.connected) {
                  return;
                }
                e.preventDefault();
                if (canCompose) {
                  props.onSend();
                }
              }}
              @input=${(e: Event) => {
                const target = e.target as HTMLTextAreaElement;
                adjustTextareaHeight(target);
                props.onDraftChange(target.value);
              }}
              @paste=${(e: ClipboardEvent) => handlePaste(e, props)}
              placeholder=${composePlaceholder}
            ></textarea>
          </label>
          <div class="chat-compose__actions">
            ${
              SpeechRecognitionCtor && rerender
                ? html`
                <button
                  class="btn chat-mic-btn ${voiceState.listening ? "chat-mic-btn--listening" : ""}"
                  type="button"
                  title=${voiceState.listening ? "Stop & send" : "Start voice input"}
                  aria-label=${voiceState.listening ? "Stop & send" : "Start voice input"}
                  @click=${() => toggleVoiceRecognition(props, rerender)}
                >
                  ${voiceState.listening ? icons.micOff : icons.mic}
                </button>
              `
                : nothing
            }
            ${
              rerender
                ? html`
                <button
                  class="btn chat-tts-btn ${voiceState.ttsEnabled ? "chat-tts-btn--active" : ""} ${voiceState.speaking ? "chat-tts-btn--speaking" : ""}"
                  type="button"
                  title=${voiceState.ttsEnabled ? "Turn off voice replies" : "Turn on voice replies"}
                  aria-label=${voiceState.ttsEnabled ? "Turn off voice replies" : "Turn on voice replies"}
                  @click=${() => toggleTts(rerender)}
                >
                  ${voiceState.ttsEnabled ? icons.volume2 : icons.volumeX}
                </button>
              `
                : nothing
            }
            <button
              class="btn"
              ?disabled=${!props.connected || (!canAbort && props.sending)}
              @click=${canAbort ? props.onAbort : props.onNewSession}
            >
              ${canAbort ? "Stop" : "New session"}
            </button>
            <button
              class="btn primary"
              ?disabled=${!props.connected}
              @click=${props.onSend}
            >
              ${isBusy ? "Queue" : "Send"}<kbd class="btn-kbd">↵</kbd>
            </button>
          </div>
        </div>
      </div>
    </section>
  `;
}

const CHAT_HISTORY_RENDER_LIMIT = 200;

function groupMessages(items: ChatItem[]): Array<ChatItem | MessageGroup> {
  const result: Array<ChatItem | MessageGroup> = [];
  let currentGroup: MessageGroup | null = null;

  for (const item of items) {
    if (item.kind !== "message") {
      if (currentGroup) {
        result.push(currentGroup);
        currentGroup = null;
      }
      result.push(item);
      continue;
    }

    const normalized = normalizeMessage(item.message);
    const role = normalizeRoleForGrouping(normalized.role);
    const timestamp = normalized.timestamp || Date.now();

    if (!currentGroup || currentGroup.role !== role) {
      if (currentGroup) {
        result.push(currentGroup);
      }
      currentGroup = {
        kind: "group",
        key: `group:${role}:${item.key}`,
        role,
        messages: [{ message: item.message, key: item.key }],
        timestamp,
        isStreaming: false,
      };
    } else {
      currentGroup.messages.push({ message: item.message, key: item.key });
    }
  }

  if (currentGroup) {
    result.push(currentGroup);
  }
  return result;
}

function buildChatItems(props: ChatProps): Array<ChatItem | MessageGroup> {
  const items: ChatItem[] = [];
  const history = Array.isArray(props.messages) ? props.messages : [];
  const tools = Array.isArray(props.toolMessages) ? props.toolMessages : [];
  const historyStart = Math.max(0, history.length - CHAT_HISTORY_RENDER_LIMIT);
  if (historyStart > 0) {
    items.push({
      kind: "message",
      key: "chat:history:notice",
      message: {
        role: "system",
        content: `Showing last ${CHAT_HISTORY_RENDER_LIMIT} messages (${historyStart} hidden).`,
        timestamp: Date.now(),
      },
    });
  }
  for (let i = historyStart; i < history.length; i++) {
    const msg = history[i];
    const normalized = normalizeMessage(msg);

    if (!props.showThinking && normalized.role.toLowerCase() === "toolresult") {
      continue;
    }

    items.push({
      kind: "message",
      key: messageKey(msg, i),
      message: msg,
    });
  }
  if (props.showThinking) {
    for (let i = 0; i < tools.length; i++) {
      items.push({
        kind: "message",
        key: messageKey(tools[i], i + history.length),
        message: tools[i],
      });
    }
  }

  if (props.stream !== null) {
    const key = `stream:${props.sessionKey}:${props.streamStartedAt ?? "live"}`;
    if (props.stream.trim().length > 0) {
      items.push({
        kind: "stream",
        key,
        text: props.stream,
        startedAt: props.streamStartedAt ?? Date.now(),
      });
    } else {
      items.push({ kind: "reading-indicator", key });
    }
  }

  return groupMessages(items);
}

function messageKey(message: unknown, index: number): string {
  const m = message as Record<string, unknown>;
  const toolCallId = typeof m.toolCallId === "string" ? m.toolCallId : "";
  if (toolCallId) {
    return `tool:${toolCallId}`;
  }
  const id = typeof m.id === "string" ? m.id : "";
  if (id) {
    return `msg:${id}`;
  }
  const messageId = typeof m.messageId === "string" ? m.messageId : "";
  if (messageId) {
    return `msg:${messageId}`;
  }
  const timestamp = typeof m.timestamp === "number" ? m.timestamp : null;
  const role = typeof m.role === "string" ? m.role : "unknown";
  if (timestamp != null) {
    return `msg:${role}:${timestamp}:${index}`;
  }
  return `msg:${role}:${index}`;
}
