# OpenClaw(Moltbot) Memory System Analysis — Corrected Consolidated Report

> Date: 2026-02-02
> Source: repos/openclaw codebase static analysis
> Verified against: workspace.ts, memory-tool.ts, memory-search.ts, memory-flush.ts,
>   handler.ts, pruner.ts, settings.ts, system-prompt.ts, manager.ts,
>   session-tool-result-guard.ts, transcript-events.ts, bootstrap-hooks.ts,
>   hooks.ts, memory-cli.ts

---

## 1. Architecture Overview

OpenClaw uses a **file-based + vector search + context pruning** 3-axis memory system.

```
~/.openclaw/workspace/
├── AGENTS.md                     <- Agent behavior definitions
├── SOUL.md                       <- Persona / tone guidelines
├── TOOLS.md                      <- Tool usage instructions
├── IDENTITY.md                   <- Agent identity
├── USER.md                       <- User preferences
├── HEARTBEAT.md                  <- Heartbeat configuration
├── BOOTSTRAP.md                  <- Custom bootstrap instructions
├── MEMORY.md                     <- Curated long-term memory (manual)
├── memory.md                     <- Alt filename for MEMORY.md (deduplicated)
├── memory/
│   ├── 2026-01-30.md             <- Daily log (append-only, written by LLM)
│   ├── 2026-01-31.md
│   └── 2026-02-01-slack-setup.md <- Auto-generated by /new hook
└── skills/                       <- Skill definitions (SKILL.md)
```

**Memory storage paths:**
- Bootstrap files: `~/.openclaw/workspace/` (per-agent via `resolveAgentWorkspaceDir()`)
- Session transcripts: `~/.openclaw/sessions/{agentId}/{sessionId}.jsonl`
- Memory index: `~/.openclaw/.state/memory/{agentId}.sqlite` (SQLite + sqlite-vec)

---

## 2. READ Path (Memory Retrieval)

### 2.1 memory_search (tool_use)

```
Type:     LLM-invoked tool (tool_use)
Location: src/agents/tools/memory-tool.ts
Prompt:   "Before answering anything about prior work, decisions, dates,
           people, preferences, or todos: run memory_search"
```

| Field | Value | Source |
|-------|-------|--------|
| Search targets | MEMORY.md + memory/*.md + session transcripts (optional) | manager.ts |
| Search mode | Hybrid (vector + text) | memory-search.ts:82 |
| Vector weight | 0.7 (default) | memory-search.ts:83 |
| Text weight | 0.3 (default) | memory-search.ts:84 |
| Embedding providers | `"openai" \| "gemini" \| "local" \| "auto"` | memory-search.ts:12 |
| Default embedding model (Gemini) | `gemini-embedding-001` | memory-search.ts:74 |
| Default embedding model (local) | `embeddinggemma-300M-Q8_0.gguf` (~0.6GB) | docs/concepts/memory.md |
| Storage | SQLite + sqlite-vec vector extension | sqlite-vec.ts |
| maxResults | 6 | memory-search.ts:80 |
| minScore | 0.35 | memory-search.ts:81 |
| Snippet max chars | 700 | manager.ts:90 |

### 2.2 memory_get (tool_use)

```
Type:     LLM-invoked tool (tool_use)
Location: src/agents/tools/memory-tool.ts
Purpose:  Pull specific lines from memory_search results to save context
```

### 2.3 MEMORY.md Bootstrap Injection

At session start, the bootstrap loader reads fixed files and injects them
into the system prompt under `# Project Context`.

```
Session start
  → loadWorkspaceBootstrapFiles(dir)        [workspace.ts:237]
      Loads in order:
        1. AGENTS.md
        2. SOUL.md
        3. TOOLS.md
        4. IDENTITY.md
        5. USER.md
        6. HEARTBEAT.md
        7. BOOTSTRAP.md
        8. MEMORY.md (or memory.md, deduplicated) [workspace.ts:274]
  → filterBootstrapFilesForSession()        [workspace.ts:295]
      Subagent sessions filter to AGENTS.md + TOOLS.md only
  → applyBootstrapHookOverrides()           [bootstrap-hooks.ts:7]
      Internal hooks can mutate the bootstrapFiles array
  → buildAgentSystemPrompt()                [system-prompt.ts]
      "# Project Context" section: all bootstrap file contents injected
      "## Memory Recall" section: instructs LLM to use memory_search/memory_get
  → Truncation: DEFAULT_BOOTSTRAP_MAX_CHARS = 20,000 chars per file
```

**CORRECTION from original report:**
- MEMORY.md is injected as part of `# Project Context`, and there is a
  separate `## Memory Recall` section that instructs the LLM to use
  memory_search/memory_get tools. The original report conflated these.

### 2.4 Daily Logs (memory/YYYY-MM-DD.md)

**CORRECTION:** Daily log files under `memory/` are **NOT** automatically
injected at session start. `loadWorkspaceBootstrapFiles()` only loads
fixed-name files (AGENTS.md, SOUL.md, MEMORY.md, etc.). Daily logs are
discoverable via `memory_search` tool (vector search), not via bootstrap
injection. The original report's claim that "today + yesterday logs are
auto-referenced at session start" is incorrect per the codebase.

---

## 3. WRITE Path (Memory Storage)

### 3.1 /new Command Hook (Manual Trigger)

```
Location: src/hooks/bundled/session-memory/handler.ts
Trigger:  User sends /new command
Event:    triggerInternalHook("command", "new", sessionKey, context)
```

**Flow:**
1. Hook receives `event.context.previousSessionEntry.sessionFile` (JSONL path)
2. `getRecentSessionContent(sessionFile, messageCount)` parses JSONL directly
   - Filters `type="message"` entries with `role="user"|"assistant"`
   - Default: last **15** messages (configurable via `hooks.internal.entries.session-memory.config.messages`)
3. `generateSlugViaLLM({ sessionContent, cfg })` — dynamic import from `llm-slug-generator.js`
4. Fallback slug: HHMM timestamp if LLM unavailable
5. Writes `memory/{YYYY-MM-DD}-{slug}.md` to agent workspace

**Note:** The hook parses JSONL independently from `src/memory/session-files.ts`.
This is a duplication of JSONL parsing logic — format changes require updates
in both locations.

### 3.2 memoryFlush (Auto-trigger — Pre-compaction)

```
Location: src/auto-reply/reply/memory-flush.ts
Config:   agents.defaults.compaction.memoryFlush
Trigger:  totalTokens >= (contextWindow - reserveTokensFloor - softThresholdTokens)
```

**Exact prompts (from code):**

System prompt (`memory-flush.ts:16-20`):
```
"Pre-compaction memory flush turn. The session is near auto-compaction;
 capture durable memories to disk. You may reply, but usually NO_REPLY is correct."
```

User prompt (`memory-flush.ts:10-14`):
```
"Pre-compaction memory flush. Store durable memories now
 (use memory/YYYY-MM-DD.md; create memory/ if needed).
 If nothing to store, reply with NO_REPLY."
```

**Default settings:**

| Setting | Default | Source |
|---------|---------|--------|
| enabled | **true** | memory-flush.ts:40 (`defaults?.enabled ?? true`) |
| softThresholdTokens | 4,000 | memory-flush.ts:8 |
| reserveTokensFloor | 20,000 | pi-settings.ts |

**Threshold calculation** (`memory-flush.ts:90`):
```
threshold = contextWindow - reserveTokensFloor - softThresholdTokens
```
For Gemini 3 Pro (1M context): `threshold = 1,048,576 - 20,000 - 4,000 = 1,024,576`

**Dedup guard** (`memory-flush.ts:98-102`):
Same compaction round won't trigger memoryFlush twice
(`memoryFlushCompactionCount === compactionCount` check).

**Execution:** Silent turn (invisible to user) → LLM writes to memory/ files
→ responds with NO_REPLY → compaction proceeds.

### 3.3 Direct Model Write (User Request)

```
"Remember this" → LLM uses filesystem write tool to append to MEMORY.md
                   or memory/YYYY-MM-DD.md
```

No hook involvement — purely tool-based.

---

## 4. PRUNE Path (Context Pruning)

**CORRECTION:** The original report described this as "microcompact style"
with no details. The actual implementation is a ratio-based 2-stage strategy.

```
Location: src/agents/pi-extensions/context-pruning/
Mode:     "cache-ttl" (only active mode; "off" disables entirely)
Target:   In-memory context only (disk session history preserved)
```

### 4.1 Default Settings (`settings.ts:48-65`)

| Setting | Default | Purpose |
|---------|---------|---------|
| mode | `"cache-ttl"` | Only active mode |
| ttlMs | 300,000 (5 min) | Cache expiry for pruning decisions |
| keepLastAssistants | **3** | Protect last 3 assistant turns from pruning |
| softTrimRatio | **0.3** | Start soft trim when context >= 30% of window |
| hardClearRatio | **0.5** | Start hard clear when context >= 50% of window |
| minPrunableToolChars | 50,000 | Minimum prunable chars before hard clear |
| softTrim.maxChars | 4,000 | Tool results above this get trimmed |
| softTrim.headChars | 1,500 | Keep first 1500 chars |
| softTrim.tailChars | 1,500 | Keep last 1500 chars |
| hardClear.enabled | true | Allow full tool result replacement |
| hardClear.placeholder | `"[Old tool result content cleared]"` | Replacement text |

### 4.2 Pruning Algorithm (`pruner.ts:225-346`)

```
1. Calculate charWindow = contextWindowTokens * 4 (chars-per-token estimate)
2. Find cutoff index: last N assistant messages are protected (keepLastAssistants=3)
3. Find first user message index: everything before it is NEVER pruned
   (protects bootstrap identity reads: SOUL.md, USER.md, etc.)
4. Calculate ratio = totalContextChars / charWindow

Stage 1 — Soft Trim (ratio >= 0.3):
  For each prunable toolResult in [firstUserIndex..cutoffIndex]:
    If text length > softTrim.maxChars (4000):
      Keep first 1500 chars + "..." + last 1500 chars
      Append "[Tool result trimmed: kept first X chars and last Y chars of Z chars.]"
    Image tool results are SKIPPED (never soft-trimmed)

Stage 2 — Hard Clear (ratio >= 0.5 after soft trim):
  If total prunable tool chars >= minPrunableToolChars (50,000):
    Replace entire tool result content with "[Old tool result content cleared]"
    Process oldest-first until ratio drops below hardClearRatio
```

**Tool prunability** (`tools.ts`): Configurable allow/deny lists. By default
all tool results are prunable except those in the protected tail.

---

## 5. Infrastructure

### 5.1 CLI Commands (`src/cli/memory-cli.ts`)

| Subcommand | Description | Line |
|------------|-------------|------|
| `openclaw memory status` | Show memory search index status | :480 |
| `openclaw memory index` | Reindex memory files | :492 |
| `openclaw memory search <query>` | Search memory files | :619 |

**CORRECTION:** The original report listed a `prune` CLI subcommand. This does
not exist. Context pruning is a runtime extension (`pi-extensions/context-pruning/`)
that runs automatically during agent turns, not a CLI command.

### 5.2 File Watching & Sync (`src/memory/manager.ts`)

| Trigger | Default | Mechanism |
|---------|---------|-----------|
| onSessionStart | **true** | Syncs when a new session begins (once per session key) |
| onSearch | **true** | Syncs before search if index is dirty |
| watch | **true** | chokidar watches MEMORY.md + memory/ for changes |
| watchDebounceMs | **1,500ms** | Debounce for file change events |
| intervalMinutes | **0** (disabled) | Periodic sync (off by default) |

**Session transcript sync:**
| Setting | Default | Purpose |
|---------|---------|---------|
| deltaBytes | 100,000 | Re-index after 100KB of new transcript data |
| deltaMessages | 50 | Re-index after 50 new messages |
| SESSION_DIRTY_DEBOUNCE_MS | 5,000ms | Debounce for transcript update events |

**Reactive pipeline:**
```
sessionManager.appendMessage()
  → guardedAppend()                [session-tool-result-guard.ts:98]
  → emitSessionTranscriptUpdate()  [transcript-events.ts:16]
  → MemoryIndexManager listener   [manager.ts:888]
  → scheduleSessionDirty()         (5s debounce)
  → sync when delta threshold reached
```

### 5.3 Agent Scoping

- Each agent has isolated memory via `agentSessionKey`
- Separate SQLite index per agent (`~/.openclaw/.state/memory/{agentId}.sqlite`)
- Separate workspace directory per agent
- `warmSession()` tracks per-session dedup to avoid redundant syncs

### 5.4 Embedding Configuration

| Provider | Model | Storage | Batch Support |
|----------|-------|---------|---------------|
| OpenAI | configurable | SQLite | Yes (API batch) |
| Gemini | `gemini-embedding-001` | SQLite | Yes (async batch, max 50k requests) |
| Local | `embeddinggemma-300M-Q8_0.gguf` (~0.6GB) | SQLite | No |
| auto | Tries providers in order | SQLite | Varies |

**Embedding constants:**
| Constant | Value | Source |
|----------|-------|--------|
| EMBEDDING_BATCH_MAX_TOKENS | 8,000 | manager.ts:96 |
| EMBEDDING_INDEX_CONCURRENCY | 4 | manager.ts:98 |
| EMBEDDING_RETRY_MAX_ATTEMPTS | 3 | manager.ts:99 |
| VECTOR_LOAD_TIMEOUT_MS | 30,000 | manager.ts |
| EMBEDDING_QUERY_TIMEOUT_LOCAL_MS | 300,000 (5 min) | manager.ts |
| Chunk tokens | 400 | memory-search.ts:75 |
| Chunk overlap | 80 | memory-search.ts:76 |

---

## 6. Hook ↔ Memory Dependency Map

### 6.1 Five Dependency Paths

```
Path ①  Bootstrap Hook → Memory Context Injection    (session start)
Path ②  session-memory Hook → Memory File Creation   (/new command)
Path ③  memoryFlush → Pre-compaction Auto-save        (token threshold)
Path ④  tool_result_persist Hook → Session Write      (tool execution)
Path ⑤  Transcript Event → Memory Index Sync          (realtime)
```

### 6.2 Path Details

**Path ① (Hook → Memory, READ)**
```
Session start → loadWorkspaceBootstrapFiles()
  → applyBootstrapHookOverrides()   [Internal Hook: agent:bootstrap]
    Hooks can mutate bootstrapFiles array (add/remove/replace MEMORY.md)
  → buildAgentSystemPrompt()
    MEMORY.md content injected into "# Project Context"
  → hookRunner.runBeforeAgentStart() [Plugin Hook: before_agent_start]
    Can inject prependContext or override systemPrompt
```

**Path ② (Hook → Memory, WRITE)**
```
/new command → triggerInternalHook("command", "new")
  → session-memory handler reads JSONL directly
  → Writes memory/{date}-{slug}.md
  → chokidar detects new file → marks index dirty
  → Next memory_search triggers re-index
```

**Path ③ (Auto → Memory, WRITE)**
```
Agent turn → shouldRunMemoryFlush() checks token count
  → Silent turn: LLM writes to memory/ files
  → NO_REPLY response
  → Compaction proceeds
  → Plugin Hooks: before_compaction / after_compaction (fire-and-forget)
```

**Path ④ (Plugin Hook → Session, WRITE)**
```
Tool execution → toolResult generated
  → sessionManager.appendMessage() [monkey-patched]
  → tool_result_persist Plugin Hook (SYNCHRONOUS, sequential)
    Each handler can transform the message before persistence
  → Transformed message written to JSONL
```

**Path ⑤ (Session → Index, REACTIVE)**
```
JSONL append → emitSessionTranscriptUpdate()
  → MemoryIndexManager listener (agent-scoped filter)
  → 5s debounce → delta threshold check
  → sync: parse JSONL → chunk → embed → SQLite write
```

---

## 7. Known Issues & Architectural Concerns

### 7.1 memoryFlush Non-deterministic Results
- memoryFlush is `enabled: true` by default (`memory-flush.ts:40`)
- However, LLM may respond with NO_REPLY without saving anything meaningful
- No verification step exists to confirm data was actually persisted
- Compaction proceeds regardless of flush outcome

### 7.2 JSONL Parsing Duplication
- `session-memory/handler.ts` parses JSONL independently (lines 30-51)
- `src/memory/session-files.ts` has its own JSONL parser (`buildSessionEntry`)
- Format changes require updates in both locations

### 7.3 Context Pruning Visibility
- Agents have no awareness of their own context utilization percentage
- Pruning activates silently at 30% (soft) and 50% (hard) ratios
- No user-facing indication that pruning has occurred

### 7.4 Compaction Failure on Large Sessions
- Compaction requires summarizing the full context
- If session exceeds model output limits, compaction summary itself can fail
- `before_compaction` Plugin Hook is fire-and-forget (void hook)
  — cannot block or delay compaction

### 7.5 24-hour Unattended Operation
- `/new` hook requires manual trigger — no one to press it in headless mode
- memoryFlush is the only automatic memory preservation mechanism
- For Gemini 3 Pro with 1M context window, threshold is ~1M tokens
  — memoryFlush may never trigger in normal usage because context rarely
  fills to that level before session ends

### 7.6 Race Condition: Bootstrap vs. Memory Write
- Path ① reads MEMORY.md at session start
- Path ③ writes memory/ files during pre-compaction
- If another session starts while memoryFlush is writing, it may read
  an incomplete file (`fs.writeFile` is not atomic)

### 7.7 Plugin Hook Chain Contract
- `tool_result_persist` (Path ④) chains multiple plugins sequentially
- No contract between plugins on expected message shape
- Plugin A removing a field silently breaks Plugin B downstream

---

## 8. Source File Map

| File | Location | Role |
|------|----------|------|
| memory-tool.ts | `src/agents/tools/` | memory_search + memory_get tool definitions |
| memory-search.ts | `src/agents/` | Search config resolution (defaults, provider, weights) |
| workspace.ts | `src/agents/` | Bootstrap file loading (MEMORY.md, AGENTS.md, etc.) |
| bootstrap-files.ts | `src/agents/` | Bootstrap file resolution for agent runs |
| bootstrap-hooks.ts | `src/agents/` | Internal hook: agent:bootstrap (mutate bootstrap files) |
| system-prompt.ts | `src/agents/` | System prompt assembly (Project Context, Memory Recall) |
| handler.ts | `src/hooks/bundled/session-memory/` | /new hook handler (session summary to memory file) |
| memory-flush.ts | `src/auto-reply/reply/` | memoryFlush logic (thresholds, prompts, settings) |
| agent-runner-memory.ts | `src/auto-reply/` | memoryFlush trigger integration with agent runner |
| pruner.ts | `src/agents/pi-extensions/context-pruning/` | 2-stage pruning algorithm (soft trim + hard clear) |
| settings.ts | `src/agents/pi-extensions/context-pruning/` | Pruning config defaults and resolution |
| tools.ts | `src/agents/pi-extensions/context-pruning/` | Tool prunability predicate (allow/deny lists) |
| manager.ts | `src/memory/` | Memory engine core (indexing, search, sync, watching) |
| sync-memory-files.ts | `src/memory/` | Memory file sync (MEMORY.md + memory/*.md → index) |
| sync-session-files.ts | `src/memory/` | Session transcript sync (JSONL → index) |
| session-files.ts | `src/memory/` | Session JSONL parser (buildSessionEntry) |
| sqlite-vec.ts | `src/memory/` | SQLite vector extension loader |
| embeddings-gemini.ts | `src/memory/` | Gemini embedding API client |
| batch-gemini.ts | `src/memory/` | Gemini batch embedding submission & polling |
| pi-tools.ts | `src/agents/` | Tool creation + hook wrapping orchestration |
| pi-tools.before-tool-call.ts | `src/agents/` | before_tool_call hook wrapper for all tools |
| session-tool-result-guard.ts | `src/agents/` | tool_result_persist hook + JSONL append guard |
| transcript-events.ts | `src/sessions/` | Session transcript update event emitter |
| hooks.ts | `src/plugins/` | Plugin hook runner (14 hook types) |
| hook-runner-global.ts | `src/plugins/` | Global hook runner singleton |
| internal-hooks.ts | `src/hooks/` | Internal hook registry (command, agent, gateway events) |
| loader.ts | `src/hooks/` | Hook loader (bundled, managed, workspace, plugin) |
| memory-cli.ts | `src/cli/` | CLI: `openclaw memory {status,index,search}` |

---

## 9. Corrections from Original Report

| Section | Original Claim | Correction |
|---------|---------------|------------|
| 2.3 | "Project Context에 주입" | MEMORY.md는 `# Project Context`에, memory_search 안내는 별도 `## Memory Recall` 섹션에 위치. 두 개는 별개 |
| 2.4 | "오늘 + 어제 일별 로그를 자동 참조" | **False.** `loadWorkspaceBootstrapFiles()`는 고정 파일만 로드. memory/*.md는 `memory_search` 도구로만 접근 가능 |
| 3.2 prompt | "Session nearing compaction..." | 실제: `"Pre-compaction memory flush turn. The session is near auto-compaction; capture durable memories to disk."` |
| 3.2 default | "기본값이 꺼져 있거나..." | **False.** `enabled: true`가 기본값 (`memory-flush.ts:40`). "많은 유저가 모름"은 코드로 검증 불가한 주관적 진술 |
| 4 | "microcompact 스타일" (세부 없음) | 실제: ratio-based 2-stage (soft trim at 30%, hard clear at 50%), keepLastAssistants=3, bootstrap protection |
| 5 CLI | `prune` 서브커맨드 존재 | **False.** CLI는 `status`, `index`, `search` 3개만. 프루닝은 런타임 확장이며 CLI 명령 아님 |
| 7 map | 5개 파일 누락 | memory-flush.ts, bootstrap-hooks.ts, agent-runner-memory.ts, pi-tools.ts, manager.ts 등 추가 |
| 6.1 | "기본값이 꺼져 있거나 설정을 안 해서" | `enabled ?? true`로 기본 활성. 문제는 default-off가 아니라 LLM이 NO_REPLY할 수 있다는 비결정성 |

---

*This report was compiled from static analysis of the openclaw codebase.
Issue numbers (#5429, #2597, #1808, #5433) referenced in the original report
could not be verified within this codebase and require GitHub API confirmation.*
