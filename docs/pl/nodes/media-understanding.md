---
summary: "Rozumienie przychodzÄ…cych obrazÃ³w/dÅºwiÄ™ku/wideo (opcjonalne) z uÅ¼yciem dostawcy oraz mechanizmÃ³w awaryjnych CLI"
read_when:
  - Projektowanie lub refaktoryzacja rozumienia mediÃ³w
  - Strojenie przetwarzania wstÄ™pnego przychodzÄ…cych nagraÅ„ audio/wideo/obrazÃ³w
title: "Rozumienie mediÃ³w"
---

# Rozumienie mediÃ³w (przychodzÄ…cych) â€” 2026-01-17

OpenClaw moÅ¼e **podsumowywaÄ‡ przychodzÄ…ce media** (obraz/dÅºwiÄ™k/wideo) zanim uruchomi siÄ™ potok odpowiedzi. System automatycznie wykrywa dostÄ™pnoÅ›Ä‡ narzÄ™dzi lokalnych lub kluczy dostawcÃ³w i moÅ¼e zostaÄ‡ wyÅ‚Ä…czony albo dostosowany. JeÅ›li rozumienie jest wyÅ‚Ä…czone, modele nadal otrzymujÄ… oryginalne pliki/adresy URL jak zwykle.

## Cele

- Opcjonalnie: wstÄ™pne â€strawienieâ€ przychodzÄ…cych mediÃ³w do krÃ³tkiego tekstu dla szybszego routingu i lepszego parsowania poleceÅ„.
- Zachowanie oryginalnego dostarczania mediÃ³w do modelu (zawsze).
- ObsÅ‚uga **API dostawcÃ³w** oraz **mechanizmÃ³w awaryjnych CLI**.
- UmoÅ¼liwienie wielu modeli z uporzÄ…dkowanym fallbackiem (bÅ‚Ä…d/rozmiar/limit czasu).

## Zachowanie wysokiego poziomu

1. Zbieranie przychodzÄ…cych zaÅ‚Ä…cznikÃ³w (`MediaPaths`, `MediaUrls`, `MediaTypes`).
2. Dla kaÅ¼dej wÅ‚Ä…czonej moÅ¼liwoÅ›ci (obraz/dÅºwiÄ™k/wideo) wybÃ³r zaÅ‚Ä…cznikÃ³w zgodnie z politykÄ… (domyÅ›lnie: **pierwszy**).
3. WybÃ³r pierwszego kwalifikujÄ…cego siÄ™ wpisu modelu (rozmiar + moÅ¼liwoÅ›ci + uwierzytelnienie).
4. JeÅ›li model zawiedzie lub media sÄ… zbyt duÅ¼e, **nastÄ™puje przejÅ›cie do nastÄ™pnego wpisu**.
5. Po sukcesie:
   - `Body` staje siÄ™ blokiem `[Image]`, `[Audio]` lub `[Video]`.
   - Audio ustawia `{{Transcript}}`; parsowanie poleceÅ„ uÅ¼ywa tekstu podpisu, jeÅ›li jest obecny,
     w przeciwnym razie transkrypcji.
   - Podpisy sÄ… zachowywane jako `User text:` wewnÄ…trz bloku.

JeÅ›li rozumienie siÄ™ nie powiedzie lub jest wyÅ‚Ä…czone, **przepÅ‚yw odpowiedzi jest kontynuowany** z oryginalnym treÅ›ciÄ… + zaÅ‚Ä…cznikami.

## PrzeglÄ…d konfiguracji

`tools.media` obsÅ‚uguje **modele wspÃ³Å‚dzielone** oraz nadpisania perâ€‘moÅ¼liwoÅ›Ä‡:

- `tools.media.models`: lista modeli wspÃ³Å‚dzielonych (uÅ¼yj `capabilities` do ograniczeÅ„).
- `tools.media.image` / `tools.media.audio` / `tools.media.video`:
  - domyÅ›lne (`prompt`, `maxChars`, `maxBytes`, `timeoutSeconds`, `language`)
  - nadpisania dostawcy (`baseUrl`, `headers`, `providerOptions`)
  - opcje audio Deepgram przez `tools.media.audio.providerOptions.deepgram`
  - opcjonalna **lista `models` perâ€‘moÅ¼liwoÅ›Ä‡** (preferowana przed modelami wspÃ³Å‚dzielonymi)
  - polityka `attachments` (`mode`, `maxAttachments`, `prefer`)
  - `scope` (opcjonalne ograniczanie wedÅ‚ug kanaÅ‚u/chatType/klucza sesji)
- `tools.media.concurrency`: maksymalna liczba rÃ³wnolegÅ‚ych uruchomieÅ„ moÅ¼liwoÅ›ci (domyÅ›lnie **2**).

```json5
{
  tools: {
    media: {
      models: [
        /* shared list */
      ],
      image: {
        /* optional overrides */
      },
      audio: {
        /* optional overrides */
      },
      video: {
        /* optional overrides */
      },
    },
  },
}
```

### Wpisy modeli

KaÅ¼dy wpis `models[]` moÅ¼e byÄ‡ **dostawcÄ…** lub **CLI**:

```json5
{
  type: "provider", // default if omitted
  provider: "openai",
  model: "gpt-5.2",
  prompt: "Describe the image in <= 500 chars.",
  maxChars: 500,
  maxBytes: 10485760,
  timeoutSeconds: 60,
  capabilities: ["image"], // optional, used for multiâ€‘modal entries
  profile: "vision-profile",
  preferredProfile: "vision-fallback",
}
```

```json5
{
  type: "cli",
  command: "gemini",
  args: [
    "-m",
    "gemini-3-flash",
    "--allowed-tools",
    "read_file",
    "Read the media at {{MediaPath}} and describe it in <= {{MaxChars}} characters.",
  ],
  maxChars: 500,
  maxBytes: 52428800,
  timeoutSeconds: 120,
  capabilities: ["video", "image"],
}
```

Szablony CLI mogÄ… takÅ¼e uÅ¼ywaÄ‡:

- `{{MediaDir}}` (katalog zawierajÄ…cy plik multimedialny)
- `{{OutputDir}}` (katalog tymczasowy utworzony na to uruchomienie)
- `{{OutputBase}}` (bazowa Å›cieÅ¼ka pliku tymczasowego, bez rozszerzenia)

## Ustawienia domyÅ›lne i limity

Zalecane ustawienia domyÅ›lne:

- `maxChars`: **500** dla obrazu/wideo (krÃ³tkie, przyjazne dla poleceÅ„)
- `maxChars`: **nieustawione** dla audio (peÅ‚na transkrypcja, chyba Å¼e ustawisz limit)
- `maxBytes`:
  - obraz: **10MB**
  - audio: **20MB**
  - wideo: **50MB**

Zasady:

- JeÅ›li media przekraczajÄ… `maxBytes`, ten model jest pomijany i **prÃ³bowany jest nastÄ™pny model**.
- JeÅ›li model zwrÃ³ci wiÄ™cej niÅ¼ `maxChars`, wynik jest przycinany.
- `prompt` domyÅ›lnie uÅ¼ywa prostego â€Describe the {media}.â€ plus wskazÃ³wek `maxChars` (tylko obraz/wideo).
- JeÅ›li `<capability>.enabled: true`, ale nie skonfigurowano modeli, OpenClaw prÃ³buje uÅ¼yÄ‡
  **aktywnego modelu odpowiedzi**, gdy jego dostawca obsÅ‚uguje danÄ… moÅ¼liwoÅ›Ä‡.

### Automatyczne wykrywanie rozumienia mediÃ³w (domyÅ›lnie)

JeÅ›li `tools.media.<capability>.enabled` **nie** jest ustawione na `false` i nie skonfigurowano
modeli, OpenClaw automatycznie wykrywa w tej kolejnoÅ›ci i **zatrzymuje siÄ™ na pierwszej
dziaÅ‚ajÄ…cej opcji**:

1. **Lokalne CLI** (tylko audio; jeÅ›li zainstalowane)
   - `sherpa-onnx-offline` (wymaga `SHERPA_ONNX_MODEL_DIR` z enkoderem/dekoderem/Å‚Ä…cznikiem/tokenami)
   - `whisper-cli` (`whisper-cpp`; uÅ¼ywa `WHISPER_CPP_MODEL` lub doÅ‚Ä…czonego maÅ‚ego modelu)
   - `whisper` (CLI w Pythonie; automatycznie pobiera modele)
2. **Gemini CLI** (`gemini`) z uÅ¼yciem `read_many_files`
3. **Klucze dostawcÃ³w**
   - Audio: OpenAI â†’ Groq â†’ Deepgram â†’ Google
   - Obraz: OpenAI â†’ Anthropic â†’ Google â†’ MiniMax
   - Wideo: Google

Aby wyÅ‚Ä…czyÄ‡ automatyczne wykrywanie, ustaw:

```json5
{
  tools: {
    media: {
      audio: {
        enabled: false,
      },
    },
  },
}
```

Uwaga: wykrywanie binariÃ³w jest realizowane w trybie bestâ€‘effort na macOS/Linux/Windows; upewnij siÄ™, Å¼e CLI znajduje siÄ™ w `PATH` (rozwijamy `~`), lub ustaw jawny model CLI z peÅ‚nÄ… Å›cieÅ¼kÄ… do polecenia.

## MoÅ¼liwoÅ›ci (opcjonalnie)

JeÅ›li ustawisz `capabilities`, wpis uruchamia siÄ™ tylko dla tych typÃ³w mediÃ³w. Dla list
wspÃ³Å‚dzielonych OpenClaw moÅ¼e wywnioskowaÄ‡ wartoÅ›ci domyÅ›lne:

- `openai`, `anthropic`, `minimax`: **obraz**
- `google` (Gemini API): **obraz + audio + wideo**
- `groq`: **audio**
- `deepgram`: **audio**

Dla wpisÃ³w CLI **ustaw `capabilities` jawnie**, aby uniknÄ…Ä‡ nieoczekiwanych dopasowaÅ„.
JeÅ›li pominiesz `capabilities`, wpis kwalifikuje siÄ™ do listy, w ktÃ³rej siÄ™ znajduje.

## Macierz obsÅ‚ugi dostawcÃ³w (integracje OpenClaw)

| MoÅ¼liwoÅ›Ä‡ | Integracja dostawcy                              | Uwagi                                                                               |
| --------- | ------------------------------------------------ | ----------------------------------------------------------------------------------- |
| Obraz     | OpenAI / Anthropic / Google / inne przez `pi-ai` | KaÅ¼dy model obsÅ‚ugujÄ…cy obrazy w rejestrze dziaÅ‚a.                  |
| Audio     | OpenAI, Groq, Deepgram, Google                   | Transkrypcja dostawcy (Whisper/Deepgram/Gemini). |
| Wideo     | Google (Gemini API)           | Rozumienie wideo przez dostawcÄ™.                                    |

## Zalecani dostawcy

**Obraz**

- Preferuj aktywny model, jeÅ›li obsÅ‚uguje obrazy.
- Dobre ustawienia domyÅ›lne: `openai/gpt-5.2`, `anthropic/claude-opus-4-6`, `google/gemini-3-pro-preview`.

**Audio**

- `openai/gpt-4o-mini-transcribe`, `groq/whisper-large-v3-turbo` lub `deepgram/nova-3`.
- Fallback CLI: `whisper-cli` (whisper-cpp) lub `whisper`.
- Konfiguracja Deepgram: [Deepgram (transkrypcja audio)](/providers/deepgram).

**Wideo**

- `google/gemini-3-flash-preview` (szybkie), `google/gemini-3-pro-preview` (bogatsze).
- Fallback CLI: CLI `gemini` (obsÅ‚uguje `read_file` dla wideo/audio).

## Polityka zaÅ‚Ä…cznikÃ³w

`attachments` perâ€‘moÅ¼liwoÅ›Ä‡ kontroluje, ktÃ³re zaÅ‚Ä…czniki sÄ… przetwarzane:

- `mode`: `first` (domyÅ›lnie) lub `all`
- `maxAttachments`: limit liczby przetwarzanych (domyÅ›lnie **1**)
- `prefer`: `first`, `last`, `path`, `url`

Gdy `mode: "all"`, wyniki sÄ… oznaczane jako `[Image 1/2]`, `[Audio 2/2]` itd.

## PrzykÅ‚ady konfiguracji

### 1. Lista modeli wspÃ³Å‚dzielonych + nadpisania

```json5
{
  tools: {
    media: {
      models: [
        { provider: "openai", model: "gpt-5.2", capabilities: ["image"] },
        {
          provider: "google",
          model: "gemini-3-flash-preview",
          capabilities: ["image", "audio", "video"],
        },
        {
          type: "cli",
          command: "gemini",
          args: [
            "-m",
            "gemini-3-flash",
            "--allowed-tools",
            "read_file",
            "Read the media at {{MediaPath}} and describe it in <= {{MaxChars}} characters.",
          ],
          capabilities: ["image", "video"],
        },
      ],
      audio: {
        attachments: { mode: "all", maxAttachments: 2 },
      },
      video: {
        maxChars: 500,
      },
    },
  },
}
```

### 2. Tylko audio + wideo (obraz wyÅ‚Ä…czony)

```json5
{
  tools: {
    media: {
      audio: {
        enabled: true,
        models: [
          { provider: "openai", model: "gpt-4o-mini-transcribe" },
          {
            type: "cli",
            command: "whisper",
            args: ["--model", "base", "{{MediaPath}}"],
          },
        ],
      },
      video: {
        enabled: true,
        maxChars: 500,
        models: [
          { provider: "google", model: "gemini-3-flash-preview" },
          {
            type: "cli",
            command: "gemini",
            args: [
              "-m",
              "gemini-3-flash",
              "--allowed-tools",
              "read_file",
              "Read the media at {{MediaPath}} and describe it in <= {{MaxChars}} characters.",
            ],
          },
        ],
      },
    },
  },
}
```

### 3. Opcjonalne rozumienie obrazu

```json5
{
  tools: {
    media: {
      image: {
        enabled: true,
        maxBytes: 10485760,
        maxChars: 500,
        models: [
          { provider: "openai", model: "gpt-5.2" },
          { provider: "anthropic", model: "claude-opus-4-6" },
          {
            type: "cli",
            command: "gemini",
            args: [
              "-m",
              "gemini-3-flash",
              "--allowed-tools",
              "read_file",
              "Read the media at {{MediaPath}} and describe it in <= {{MaxChars}} characters.",
            ],
          },
        ],
      },
    },
  },
}
```

### 4. Pojedynczy wpis multimodalny (jawne moÅ¼liwoÅ›ci)

```json5
{
  tools: {
    media: {
      image: {
        models: [
          {
            provider: "google",
            model: "gemini-3-pro-preview",
            capabilities: ["image", "video", "audio"],
          },
        ],
      },
      audio: {
        models: [
          {
            provider: "google",
            model: "gemini-3-pro-preview",
            capabilities: ["image", "video", "audio"],
          },
        ],
      },
      video: {
        models: [
          {
            provider: "google",
            model: "gemini-3-pro-preview",
            capabilities: ["image", "video", "audio"],
          },
        ],
      },
    },
  },
}
```

## WyjÅ›cie statusu

Gdy dziaÅ‚a rozumienie mediÃ³w, `/status` zawiera krÃ³tkÄ… liniÄ™ podsumowania:

```
ğŸ“ Media: image ok (openai/gpt-5.2) Â· audio skipped (maxBytes)
```

Pokazuje to wyniki perâ€‘moÅ¼liwoÅ›Ä‡ oraz wybranego dostawcÄ™/model, gdy ma to zastosowanie.

## Uwagi

- Rozumienie dziaÅ‚a w trybie **bestâ€‘effort**. BÅ‚Ä™dy nie blokujÄ… odpowiedzi.
- ZaÅ‚Ä…czniki sÄ… nadal przekazywane do modeli nawet wtedy, gdy rozumienie jest wyÅ‚Ä…czone.
- UÅ¼yj `scope`, aby ograniczyÄ‡ miejsca, w ktÃ³rych uruchamia siÄ™ rozumienie (np. tylko DMâ€‘y).

## PowiÄ…zana dokumentacja

- [Konfiguracja](/gateway/configuration)
- [ObsÅ‚uga obrazÃ³w i mediÃ³w](/nodes/images)
