---
summary: "Comprensi√≥n de imagen/audio/video entrante (opcional) con respaldos de proveedor + CLI"
read_when:
  - Dise√±ar o refactorizar comprensi√≥n de medios
  - Ajustar preprocesamiento de audio/video/imagen entrante
title: "Comprensi√≥n de Medios"
---

# Comprensi√≥n de Medios (Entrante) ‚Äî 2026-01-17

OpenClaw puede **resumir medios entrantes** (imagen/audio/video) antes de que se ejecute el pipeline de respuesta. Detecta autom√°ticamente cuando las herramientas locales o claves de proveedor est√°n disponibles, y puede deshabilitarse o personalizarse. Si la comprensi√≥n est√° desactivada, los modelos a√∫n reciben los archivos/URLs originales como de costumbre.

## Objetivos

- Opcional: pre-digerir medios entrantes en texto corto para enrutamiento m√°s r√°pido + mejor an√°lisis de comandos.
- Preservar la entrega de medios originales al modelo (siempre).
- Admitir **APIs de proveedor** y **respaldos CLI**.
- Permitir m√∫ltiples modelos con respaldo ordenado (error/tama√±o/tiempo de espera).

## Comportamiento de alto nivel

1. Recopilar adjuntos entrantes (`MediaPaths`, `MediaUrls`, `MediaTypes`).
2. Para cada capacidad habilitada (imagen/audio/video), seleccionar adjuntos seg√∫n pol√≠tica (predeterminado: **primero**).
3. Elegir la primera entrada de modelo elegible (tama√±o + capacidad + autenticaci√≥n).
4. Si un modelo falla o el medio es demasiado grande, **recurrir a la siguiente entrada**.
5. En caso de √©xito:
   - `Body` se convierte en bloque `[Image]`, `[Audio]` o `[Video]`.
   - El audio establece `{{Transcript}}`; el an√°lisis de comandos usa texto de subt√≠tulo cuando est√° presente,
     de lo contrario la transcripci√≥n.
   - Los subt√≠tulos se preservan como `Texto del usuario:` dentro del bloque.

Si la comprensi√≥n falla o est√° deshabilitada, **el flujo de respuesta contin√∫a** con el cuerpo original + adjuntos.

## Resumen de configuraci√≥n

`tools.media` admite **modelos compartidos** m√°s anulaciones por capacidad:

- `tools.media.models`: lista de modelos compartida (usar `capabilities` para controlar).
- `tools.media.image` / `tools.media.audio` / `tools.media.video`:
  - predeterminados (`prompt`, `maxChars`, `maxBytes`, `timeoutSeconds`, `language`)
  - anulaciones de proveedor (`baseUrl`, `headers`, `providerOptions`)
  - opciones de audio Deepgram mediante `tools.media.audio.providerOptions.deepgram`
  - opcional **lista `models` por capacidad** (preferida antes de modelos compartidos)
  - pol√≠tica `attachments` (`mode`, `maxAttachments`, `prefer`)
  - `scope` (control opcional por canal/chatType/clave de sesi√≥n)
- `tools.media.concurrency`: m√°ximo de ejecuciones de capacidad concurrentes (predeterminado **2**).

```json5
{
  tools: {
    media: {
      models: [
        /* lista compartida */
      ],
      image: {
        /* anulaciones opcionales */
      },
      audio: {
        /* anulaciones opcionales */
      },
      video: {
        /* anulaciones opcionales */
      },
    },
  },
}
```

### Entradas de modelo

Cada entrada `models[]` puede ser **proveedor** o **CLI**:

```json5
{
  type: "provider", // predeterminado si se omite
  provider: "openai",
  model: "gpt-5.2",
  prompt: "Describe la imagen en <= 500 caracteres.",
  maxChars: 500,
  maxBytes: 10485760,
  timeoutSeconds: 60,
  capabilities: ["image"], // opcional, usado para entradas multi-modal
  profile: "vision-profile",
  preferredProfile: "vision-fallback",
}
```

```json5
{
  type: "cli",
  command: "gemini",
  args: [
    "-m",
    "gemini-3-flash",
    "--allowed-tools",
    "read_file",
    "Lee el medio en {{MediaPath}} y descr√≠belo en <= {{MaxChars}} caracteres.",
  ],
  maxChars: 500,
  maxBytes: 52428800,
  timeoutSeconds: 120,
  capabilities: ["video", "image"],
}
```

Las plantillas CLI tambi√©n pueden usar:

- `{{MediaDir}}` (directorio que contiene el archivo de medios)
- `{{OutputDir}}` (directorio scratch creado para esta ejecuci√≥n)
- `{{OutputBase}}` (ruta base de archivo scratch, sin extensi√≥n)

## Predeterminados y l√≠mites

Predeterminados recomendados:

- `maxChars`: **500** para imagen/video (corto, amigable para comandos)
- `maxChars`: **no establecido** para audio (transcripci√≥n completa a menos que establezcas un l√≠mite)
- `maxBytes`:
  - imagen: **10MB**
  - audio: **20MB**
  - video: **50MB**

Reglas:

- Si el medio excede `maxBytes`, ese modelo se omite y **se intenta el siguiente modelo**.
- Si el modelo devuelve m√°s de `maxChars`, la salida se recorta.
- `prompt` predeterminado es simple "Describe el {medio}." m√°s la gu√≠a `maxChars` (solo imagen/video).
- Si `<capability>.enabled: true` pero no se configuran modelos, OpenClaw intenta el
  **modelo de respuesta activo** cuando su proveedor admite la capacidad.

### Detecci√≥n autom√°tica de comprensi√≥n de medios (predeterminado)

Si `tools.media.<capability>.enabled` **no** est√° establecido en `false` y no has configurado modelos, OpenClaw detecta autom√°ticamente en este orden y **se detiene en la primera opci√≥n que funciona**:

1. **CLIs locales** (solo audio; si est√°n instalados)
   - `sherpa-onnx-offline` (requiere `SHERPA_ONNX_MODEL_DIR` con encoder/decoder/joiner/tokens)
   - `whisper-cli` (`whisper-cpp`; usa `WHISPER_CPP_MODEL` o el modelo tiny incluido)
   - `whisper` (CLI de Python; descarga modelos autom√°ticamente)
2. **CLI Gemini** (`gemini`) usando `read_many_files`
3. **Claves de proveedor**
   - Audio: OpenAI ‚Üí Groq ‚Üí Deepgram ‚Üí Google
   - Imagen: OpenAI ‚Üí Anthropic ‚Üí Google ‚Üí MiniMax
   - Video: Google

Para deshabilitar la detecci√≥n autom√°tica, establece:

```json5
{
  tools: {
    media: {
      audio: {
        enabled: false,
      },
    },
  },
}
```

Nota: La detecci√≥n binaria es de mejor esfuerzo en macOS/Linux/Windows; aseg√∫rate de que el CLI est√© en `PATH` (expandimos `~`), o establece un modelo CLI expl√≠cito con una ruta de comando completa.

## Capacidades (opcional)

Si estableces `capabilities`, la entrada solo se ejecuta para esos tipos de medios. Para listas compartidas, OpenClaw puede inferir predeterminados:

- `openai`, `anthropic`, `minimax`: **imagen**
- `google` (API Gemini): **imagen + audio + video**
- `groq`: **audio**
- `deepgram`: **audio**

Para entradas CLI, **establece `capabilities` expl√≠citamente** para evitar coincidencias sorpresivas.
Si omites `capabilities`, la entrada es elegible para la lista en la que aparece.

## Matriz de soporte de proveedor (integraciones OpenClaw)

| Capacidad | Integraci√≥n de proveedor                             | Notas                                                             |
| --------- | ---------------------------------------------------- | ----------------------------------------------------------------- |
| Imagen    | OpenAI / Anthropic / Google / otros mediante `pi-ai` | Cualquier modelo con capacidad de imagen en el registro funciona. |
| Audio     | OpenAI, Groq, Deepgram, Google                       | Transcripci√≥n de proveedor (Whisper/Deepgram/Gemini).             |
| Video     | Google (API Gemini)                                  | Comprensi√≥n de video del proveedor.                               |

## Proveedores recomendados

**Imagen**

- Prefiere tu modelo activo si admite im√°genes.
- Buenos predeterminados: `openai/gpt-5.2`, `anthropic/claude-opus-4-6`, `google/gemini-3-pro-preview`.

**Audio**

- `openai/gpt-4o-mini-transcribe`, `groq/whisper-large-v3-turbo`, o `deepgram/nova-3`.
- Respaldo CLI: `whisper-cli` (whisper-cpp) o `whisper`.
- Configuraci√≥n Deepgram: [Deepgram (transcripci√≥n de audio)](/es-ES/providers/deepgram).

**Video**

- `google/gemini-3-flash-preview` (r√°pido), `google/gemini-3-pro-preview` (m√°s rico).
- Respaldo CLI: CLI `gemini` (admite `read_file` en video/audio).

## Pol√≠tica de adjuntos

`attachments` por capacidad controla qu√© adjuntos se procesan:

- `mode`: `first` (predeterminado) o `all`
- `maxAttachments`: limita el n√∫mero procesado (predeterminado **1**)
- `prefer`: `first`, `last`, `path`, `url`

Cuando `mode: "all"`, las salidas se etiquetan `[Image 1/2]`, `[Audio 2/2]`, etc.

## Ejemplos de configuraci√≥n

### 1) Lista de modelos compartidos + anulaciones

```json5
{
  tools: {
    media: {
      models: [
        { provider: "openai", model: "gpt-5.2", capabilities: ["image"] },
        {
          provider: "google",
          model: "gemini-3-flash-preview",
          capabilities: ["image", "audio", "video"],
        },
        {
          type: "cli",
          command: "gemini",
          args: [
            "-m",
            "gemini-3-flash",
            "--allowed-tools",
            "read_file",
            "Lee el medio en {{MediaPath}} y descr√≠belo en <= {{MaxChars}} caracteres.",
          ],
          capabilities: ["image", "video"],
        },
      ],
      audio: {
        attachments: { mode: "all", maxAttachments: 2 },
      },
      video: {
        maxChars: 500,
      },
    },
  },
}
```

### 2) Solo audio + video (imagen desactivada)

```json5
{
  tools: {
    media: {
      audio: {
        enabled: true,
        models: [
          { provider: "openai", model: "gpt-4o-mini-transcribe" },
          {
            type: "cli",
            command: "whisper",
            args: ["--model", "base", "{{MediaPath}}"],
          },
        ],
      },
      video: {
        enabled: true,
        maxChars: 500,
        models: [
          { provider: "google", model: "gemini-3-flash-preview" },
          {
            type: "cli",
            command: "gemini",
            args: [
              "-m",
              "gemini-3-flash",
              "--allowed-tools",
              "read_file",
              "Lee el medio en {{MediaPath}} y descr√≠belo en <= {{MaxChars}} caracteres.",
            ],
          },
        ],
      },
    },
  },
}
```

### 3) Comprensi√≥n de imagen opcional

```json5
{
  tools: {
    media: {
      image: {
        enabled: true,
        maxBytes: 10485760,
        maxChars: 500,
        models: [
          { provider: "openai", model: "gpt-5.2" },
          { provider: "anthropic", model: "claude-opus-4-6" },
          {
            type: "cli",
            command: "gemini",
            args: [
              "-m",
              "gemini-3-flash",
              "--allowed-tools",
              "read_file",
              "Lee el medio en {{MediaPath}} y descr√≠belo en <= {{MaxChars}} caracteres.",
            ],
          },
        ],
      },
    },
  },
}
```

### 4) Entrada √∫nica multi-modal (capacidades expl√≠citas)

```json5
{
  tools: {
    media: {
      image: {
        models: [
          {
            provider: "google",
            model: "gemini-3-pro-preview",
            capabilities: ["image", "video", "audio"],
          },
        ],
      },
      audio: {
        models: [
          {
            provider: "google",
            model: "gemini-3-pro-preview",
            capabilities: ["image", "video", "audio"],
          },
        ],
      },
      video: {
        models: [
          {
            provider: "google",
            model: "gemini-3-pro-preview",
            capabilities: ["image", "video", "audio"],
          },
        ],
      },
    },
  },
}
```

## Salida de estado

Cuando se ejecuta la comprensi√≥n de medios, `/status` incluye una l√≠nea de resumen corta:

```
üìé Medios: imagen ok (openai/gpt-5.2) ¬∑ audio omitido (maxBytes)
```

Esto muestra resultados por capacidad y el proveedor/modelo elegido cuando es aplicable.

## Notas

- La comprensi√≥n es **de mejor esfuerzo**. Los errores no bloquean respuestas.
- Los adjuntos a√∫n se pasan a los modelos incluso cuando la comprensi√≥n est√° deshabilitada.
- Usa `scope` para limitar d√≥nde se ejecuta la comprensi√≥n (ej. solo mensajes directos).

## Documentaci√≥n relacionada

- [Configuraci√≥n](/es-ES/gateway/configuration)
- [Soporte de Im√°genes y Medios](/es-ES/nodes/images)
