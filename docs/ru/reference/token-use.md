---
summary: "Как OpenClaw формирует контекст подсказки и сообщает об использовании токенов и стоимости"
read_when:
  - При объяснении использования токенов, стоимости или окон контекста
  - При отладке роста контекста или поведения уплотнения
title: "Использование токенов и стоимость"
---

# Использование токенов и стоимость

OpenClaw отслеживает **токены**, а не символы. Токены зависят от модели, но большинство
моделей в стиле OpenAI в среднем используют ~4 символа на токен для английского текста.

## Как формируется системная подсказка

OpenClaw собирает собственную системную подсказку при каждом запуске. В неё входят:

- Список инструментов + краткие описания
- Список Skills (только метаданные; инструкции подгружаются по требованию с помощью `read`)
- Инструкции по самообновлению
- Рабочее пространство + bootstrap‑файлы (`AGENTS.md`, `SOUL.md`, `TOOLS.md`, `IDENTITY.md`, `USER.md`, `HEARTBEAT.md`, `BOOTSTRAP.md` при добавлении новых). Большие файлы усекаются с помощью `agents.defaults.bootstrapMaxChars` (по умолчанию: 20000).
- Время (UTC + часовой пояс пользователя)
- Теги ответа + поведение heartbeat
- Метаданные выполнения (хост/ОС/модель/режим мышления)

Полную детализацию см. в разделе [System Prompt](/concepts/system-prompt).

## Что учитывается в окне контекста

Всё, что получает модель, учитывается в лимите контекста:

- Системная подсказка (все перечисленные выше разделы)
- История диалога (сообщения пользователя и ассистента)
- Вызовы инструментов и их результаты
- Вложения/транскрипты (изображения, аудио, файлы)
- Сводки компакции и артефакты обрезки
- Обёртки провайдера или заголовки безопасности (не видны, но учитываются)

Для практической разбивки (по каждому внедрённому файлу, инструментам, skills и размеру системной подсказки) используйте `/context list` или `/context detail`. [Context](/concepts/context).

## Как посмотреть текущее использование токенов

Используйте в чате:

- `/status` → **карточка статуса с эмодзи**, показывающая модель сеанса, использование контекста,
  входные/выходные токены последнего ответа и **оценочную стоимость** (только при использовании ключа API).
- `/usage off|tokens|full` → добавляет **подвал с использованием на каждый ответ** к каждому сообщению.
  - Сохраняется на уровне сеанса (хранится как `responseUsage`).
  - При OAuth‑аутентификации **стоимость скрыта** (только токены).
- `/usage cost` → показывает локальную сводку стоимости из журналов сеанса OpenClaw.

Другие интерфейсы:

- **TUI/Web TUI:** поддерживаются `/status` + `/usage`.
- **CLI:** `openclaw status --usage` и `openclaw channels list` показывают
  окна квот провайдера (не стоимость на ответ).

## Оценка стоимости (когда отображается)

Стоимость оценивается на основе вашей конфигурации цен модели:

```
models.providers.<provider>.models[].cost
```

Это значения в **USD за 1 млн токенов** для `input`, `output`, `cacheRead` и
`cacheWrite`. Если цены отсутствуют, OpenClaw показывает только токены. OAuth‑токены
никогда не показывают стоимость в долларах.

## Влияние TTL кэша и обрезки

Кэширование подсказок у провайдера применяется только в пределах окна TTL кэша. OpenClaw может
по желанию выполнять **обрезку по cache‑ttl**: он обрезает сеанс после истечения TTL кэша,
затем сбрасывает окно кэша, чтобы последующие запросы могли повторно использовать
свежекэшированный контекст вместо повторного кэширования всей истории. Это снижает
стоимость записи в кэш, когда сеанс простаивает дольше TTL.

Настройте это в разделе [Gateway configuration](/gateway/configuration) и см. детали поведения в
[Session pruning](/concepts/session-pruning).

Heartbeat может поддерживать кэш **тёплым** во время простоев. Если TTL кэша вашей модели равен
`1h`, установка интервала heartbeat чуть меньше этого значения (например, `55m`) позволяет
избежать повторного кэширования всей подсказки и снизить стоимость записи в кэш.

Для цен Anthropic API чтение из кэша значительно дешевле входных токенов,
в то время как запись в кэш тарифицируется с более высоким множителем. Актуальные ставки и множители TTL
см. в документации Anthropic по кэшированию подсказок:
[https://docs.anthropic.com/docs/build-with-claude/prompt-caching](https://docs.anthropic.com/docs/build-with-claude/prompt-caching)

### Пример: поддержание кэша 1 ч с помощью heartbeat

```yaml
agents:
  defaults:
    model:
      primary: "anthropic/claude-opus-4-6"
    models:
      "anthropic/claude-opus-4-6":
        params:
          cacheRetention: "long"
    heartbeat:
      every: "55m"
```

## Советы по снижению давления токенов

- Используйте `/compact` для суммаризации длинных сеансов.
- Обрезайте большие выводы инструментов в своих рабочих процессах.
- Делайте описания skills короткими (список skills внедряется в подсказку).
- Для многословной исследовательской работы предпочитайте более компактные модели.

[Skills](/tools/skills) для точной формулы накладных расходов списка skills.
