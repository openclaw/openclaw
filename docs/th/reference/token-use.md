---
summary: "วิธีที่OpenClawสร้างบริบทพรอมป์ต์และรายงานการใช้งานโทเคนและค่าใช้จ่าย"
read_when:
  - อธิบายการใช้งานโทเคน ค่าใช้จ่าย หรือขนาดหน้าต่างบริบท
  - แก้ไขปัญหาการเติบโตของบริบทหรือพฤติกรรมการบีบอัด
title: "การใช้โทเคนและค่าใช้จ่าย"
---

# การใช้โทเคนและค่าใช้จ่าย

25. OpenClaw ติดตาม **tokens** ไม่ใช่อักขระ OpenClawติดตาม **โทเคน** ไม่ใช่อักขระ โทเคนขึ้นกับโมเดล แต่โดยเฉลี่ยโมเดลสไตล์OpenAIส่วนใหญ่มีประมาณ ~4 อักขระต่อโทเคนสำหรับข้อความภาษาอังกฤษ

## วิธีสร้าง system prompt

OpenClawจะประกอบ system prompt ของตัวเองทุกครั้งที่รัน โดยประกอบด้วย: 26. ซึ่งประกอบด้วย:

- รายการเครื่องมือ + คำอธิบายสั้นๆ
- รายการSkills (เฉพาะเมทาดาทา; คำสั่งจะถูกโหลดตามต้องการด้วย `read`)
- คำสั่งการอัปเดตตนเอง
- Workspace + ไฟล์บูตสแตรป (`AGENTS.md`, `SOUL.md`, `TOOLS.md`, `IDENTITY.md`, `USER.md`, `HEARTBEAT.md`, `BOOTSTRAP.md` เมื่อมีไฟล์ใหม่) ไฟล์ขนาดใหญ่จะถูกตัดทอนด้วย `agents.defaults.bootstrapMaxChars` (ค่าเริ่มต้น: 20000) 27. ไฟล์ขนาดใหญ่จะถูกตัดทอนโดย `agents.defaults.bootstrapMaxChars` (ค่าเริ่มต้น: 20000)
- เวลา (UTC + เขตเวลาของผู้ใช้)
- แท็กการตอบกลับ + พฤติกรรมฮาร์ตบีต
- เมทาดาทารันไทม์ (โฮสต์/OS/โมเดล/การคิด)

ดูรายละเอียดครบถ้วนได้ที่ [System Prompt](/concepts/system-prompt)

## อะไรบ้างที่นับรวมในหน้าต่างบริบท

ทุกสิ่งที่โมเดลได้รับจะนับรวมในขีดจำกัดบริบท:

- System prompt (ทุกส่วนที่ระบุไว้ข้างต้น)
- ประวัติการสนทนา (ข้อความผู้ใช้ + ผู้ช่วย)
- การเรียกใช้เครื่องมือและผลลัพธ์ของเครื่องมือ
- ไฟล์แนบ/ทรานสคริปต์ (รูปภาพ เสียง ไฟล์)
- 28. สรุปการบีบอัดและอาร์ติแฟกต์จากการตัดทอน
- ตัวห่อของผู้ให้บริการหรือเฮดเดอร์ด้านความปลอดภัย (มองไม่เห็น แต่ยังถูกนับ)

สำหรับการแยกรายละเอียดเชิงปฏิบัติ (ต่อไฟล์ที่ถูกฉีด เครื่องมือ Skills และขนาด system prompt) ให้ใช้ `/context list` หรือ `/context detail` ดู [Context](/concepts/context) 29. ดู [Context](/concepts/context)

## วิธีดูการใช้งานโทเคนปัจจุบัน

ใช้คำสั่งเหล่านี้ในแชต:

- `/status` → **การ์ดสถานะที่มีอีโมจิ** แสดงโมเดลของเซสชัน การใช้บริบท
  โทเคนอินพุต/เอาต์พุตของการตอบล่าสุด และ **ค่าใช้จ่ายโดยประมาณ** (เฉพาะ API key)
- `/usage off|tokens|full` → เพิ่ม **ส่วนท้ายการใช้งานต่อการตอบหนึ่งครั้ง** ให้กับทุกคำตอบ
  - คงอยู่ต่อเซสชัน (บันทึกเป็น `responseUsage`)
  - การยืนยันตัวตนแบบOAuth **ซ่อนค่าใช้จ่าย** (แสดงเฉพาะโทเคน)
- `/usage cost` → แสดงสรุปค่าใช้จ่ายภายในเครื่องจากบันทึกเซสชันของOpenClaw

ช่องทางอื่นๆ:

- **TUI/Web TUI:** รองรับ `/status` + `/usage`
- **CLI:** `openclaw status --usage` และ `openclaw channels list` แสดง
  หน้าต่างโควตาของผู้ให้บริการ (ไม่ใช่ค่าใช้จ่ายต่อการตอบ)

## การประเมินค่าใช้จ่าย (เมื่อแสดง)

ค่าใช้จ่ายถูกประเมินจากคอนฟิกราคาของโมเดลของคุณ:

```
models.providers.<provider>.models[].cost
```

หน่วยเป็น **ดอลลาร์สหรัฐต่อ 1M โทเคน** สำหรับ `input`, `output`, `cacheRead` และ
`cacheWrite` หากไม่มีข้อมูลราคา OpenClawจะแสดงเฉพาะโทเคน โทเคนแบบOAuth
จะไม่แสดงค่าเงินดอลลาร์ 30. หากไม่มีข้อมูลราคา OpenClaw จะแสดงเฉพาะจำนวนโทเคน 31. โทเคน OAuth
ไม่เคยแสดงค่าใช้จ่ายเป็นดอลลาร์

## Cache TTL และผลกระทบจากการตัดแต่ง

32. การแคชพรอมต์ของผู้ให้บริการใช้ได้เฉพาะภายในช่วงเวลา TTL ของแคชเท่านั้น การแคชพรอมป์ต์ของผู้ให้บริการจะมีผลเฉพาะภายในช่วงเวลา cache TTL เท่านั้น OpenClawสามารถ
    รัน **cache-ttl pruning** ได้ตามตัวเลือก: ระบบจะตัดแต่งเซสชันเมื่อ cache TTL
    หมดอายุ จากนั้นรีเซ็ตหน้าต่างแคชเพื่อให้คำขอถัดไปสามารถนำบริบทที่เพิ่งแคชใหม่มาใช้ซ้ำ
    แทนการแคชประวัติทั้งหมดอีกครั้ง วิธีนี้ช่วยลดค่าใช้จ่ายในการเขียนแคชเมื่อเซสชันว่างนานเกิน TTL 33. สิ่งนี้ช่วยลดต้นทุนการเขียนแคชเมื่อเซสชันไม่ได้ใช้งานเกิน TTL

กำหนดค่าได้ใน [Gateway configuration](/gateway/configuration) และดูรายละเอียดพฤติกรรมได้ที่
[Session pruning](/concepts/session-pruning)

34. Heartbeat สามารถช่วยให้แคช **อุ่น** ต่อเนื่องข้ามช่วงที่ไม่ได้ใช้งาน ฮาร์ตบีตสามารถช่วยคงแคชให้ **อุ่น** ข้ามช่วงว่างได้ หาก cache TTL ของโมเดลของคุณคือ
    `1h` การตั้งช่วงฮาร์ตบีตให้น้อยกว่านั้นเล็กน้อย (เช่น `55m`) จะช่วยหลีกเลี่ยง
    การแคชพรอมป์ต์ทั้งหมดซ้ำ ลดค่าใช้จ่ายในการเขียนแคช

35. สำหรับราคาของ Anthropic API การอ่านจากแคชจะถูกกว่าการป้อนโทเคนอย่างมาก
    ในขณะที่การเขียนแคชจะถูกคิดค่าบริการด้วยตัวคูณที่สูงกว่า สำหรับราคาของAnthropic API การอ่านจากแคชมีราคาถูกกว่าโทเคนอินพุตอย่างมาก
    ขณะที่การเขียนแคชจะถูกคิดราคาด้วยตัวคูณที่สูงกว่า ดูอัตราล่าสุดและตัวคูณ TTL ได้ที่
    เอกสารการตั้งราคาการแคชพรอมป์ต์ของAnthropic:
    [https://docs.anthropic.com/docs/build-with-claude/prompt-caching](https://docs.anthropic.com/docs/build-with-claude/prompt-caching)

### ตัวอย่าง: รักษาแคช 1 ชั่วโมงให้คงอุ่นด้วยฮาร์ตบีต

```yaml
agents:
  defaults:
    model:
      primary: "anthropic/claude-opus-4-6"
    models:
      "anthropic/claude-opus-4-6":
        params:
          cacheRetention: "long"
    heartbeat:
      every: "55m"
```

## เคล็ดลับในการลดแรงกดดันด้านโทเคน

- ใช้ `/compact` เพื่อสรุปเซสชันที่ยาว
- ตัดทอนเอาต์พุตเครื่องมือขนาดใหญ่ในเวิร์กโฟลว์ของคุณ
- ทำคำอธิบายSkillให้สั้น (รายการSkillจะถูกฉีดเข้าไปในพรอมป์ต์)
- เลือกใช้โมเดลขนาดเล็กสำหรับงานเชิงสำรวจที่มีความยืดเยื้อ

ดู [Skills](/tools/skills) สำหรับสูตรคำนวณโอเวอร์เฮดของรายการSkillอย่างละเอียด
