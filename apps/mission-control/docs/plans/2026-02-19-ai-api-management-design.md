# AI API Management â€” Hybrid Architecture Design

**Date:** 2026-02-19
**Status:** Approved
**Scope:** openclaw-mission-control (primary), openclaw-platform (secondary)

---

## Problem Statement

The Mission Control settings UI and the AI execution engine are completely disconnected. API keys saved in settings are stored in SQLite but never read by the chat API, agents, or orchestrator. All AI calls go through the OpenClaw Gateway (WebSocket at `ws://127.0.0.1:18789`), which maintains its own separate key configuration. The settings page is a dead-end database.

### Audit Findings Summary

**API Routes:**
- API keys stored as plaintext (column named `api_key_encrypted` but isn't)
- Credit/billing checks are 100% manual â€” no real provider API calls
- Azure OpenAI test URL points to wrong endpoint (management plane, not inference)
- LM Studio health check uses `/api/tags` instead of `/v1/models`

**Settings UI:**
- Ollama discovery broken â€” response shape mismatch (`ollama.available` vs `ollamaAvailable`)
- "Save & Test" button doesn't actually test
- `HelpCircle` icon aliased to `Info` after first use (wrong icon for "Untested")
- Model section never shows gateway-down warning (error catch is silent)
- No inline edit for API keys, no credit refresh, no provider help links

**Model/Agent Wiring:**
- `configPatch()` RPC already exists on OpenClawClient (line 966) but is never called
- Gateway URL/token from settings UI (localStorage) ignored by server (reads env vars only)
- Model preference stored client-side only (localStorage), not server-side
- Agent registry is prompt-only â€” no provider/model bindings

---

## Architecture: Hybrid Gateway + Direct Fallback

### Section 1: API Key Lifecycle

When a user adds an API key:

```
User enters key in Settings UI
    â†“
Frontend calls POST /api/settings/api-keys { provider, label, api_key, base_url }
    â†“
Backend:
  1. Test key against provider API (real HTTP call)
  2. If test FAILS â†’ return error, do NOT save
  3. If test PASSES:
     a. Encrypt key with AES-256-GCM
     b. Store in SQLite api_keys table
     c. Push to gateway via client.configPatch()
     d. Return success + status
    â†“
On gateway sync failure:
  â†’ Key is saved locally with status "gateway_sync_pending"
  â†’ UI shows warning: "Saved locally, gateway sync pending"
  â†’ Background retry on next settings page load
```

On DELETE:
- Remove from SQLite
- Remove from gateway via `configPatch()`
- Gateway sync failure is non-fatal (key is removed locally regardless)

On TOGGLE (active/inactive):
- Update SQLite
- Push updated state to gateway

### Section 2: Direct-to-Provider Fallback

When the gateway is unreachable, chat and agent tasks use stored API keys directly:

```
Chat message / Agent task
    â†“
Try gateway via WebSocket (3-second timeout)
    â†“
Gateway reachable?
  YES â†’ Normal flow (gateway routes to provider)
  NO  â†’ Direct mode:
        1. Read active, tested keys from SQLite
        2. Pick provider: user preference â†’ Claude â†’ GPT â†’ Gemini â†’ Ollama
        3. Call provider API directly (OpenAI SDK / Anthropic SDK / fetch)
        4. UI shows "Direct mode" indicator
```

Direct mode provider priority:
1. User's configured model preference (if provider has active key)
2. Anthropic (Claude) â€” if key exists
3. OpenAI (GPT) â€” if key exists
4. Google (Gemini) â€” if key exists
5. Ollama local â€” if running and model registered
6. Any other active provider

### Section 3: Settings UI Bug Fixes

**Critical bugs (must fix):**

| Bug | File | Fix |
|---|---|---|
| Ollama discovery broken | `local-models-section.tsx` / `settings-types.ts` / `models/route.ts` | Align response shape: route returns flat `ollamaAvailable`/`ollamaModels` to match type |
| "Save & Test" doesn't test | `api-keys-section.tsx` | Test first via PATCH, then save via POST on success |
| Wrong icon for Untested | `ai-api-command-center.tsx` | Move `HelpCircle` import before `ProviderCard` definition |
| Model section silent error | `ai-model-section.tsx` | Add error state, check `degraded` flag in response |
| Azure test URL wrong | `api-keys/route.ts` | Use deployment-specific endpoint pattern |
| LM Studio health check | `models/route.ts` | Use `/v1/models` for non-Ollama providers |

**UX improvements:**

| Improvement | Description |
|---|---|
| One-click Connect flow | Clicking "Connect" on provider card opens add form pre-populated with that provider |
| Inline key edit | PATCH support in UI â€” edit label, key, base_url without delete-recreate |
| Credit display | Show `balance` field, `last_checked_at` timestamp, manual refresh button |
| Provider help links | Each provider card links to its API key console page |
| Gateway token toggle | Add Eye/EyeOff show/hide like other secret fields |
| Debounced gateway settings | Save on blur/Enter, not on every keystroke |
| Provider documentation | Show "Get API key" links using PROVIDER_CREDIT_URLS or similar |

### Section 4: Ollama & Local AI Integration

**Auto-discovery flow:**
1. On settings page load, ping Ollama at configured URL (default `localhost:11434`)
2. Show discovered models with name, size, and parameter count
3. One-click "Register" adds to SQLite AND pushes to gateway
4. Configurable base URL (remove hardcoded `localhost:11434` from frontend)
5. Models under 14B flagged as "small" with performance note

**Registration flow:**
```
Ollama model detected (e.g., llama3.1:70b)
    â†“
User clicks "Register"
    â†“
POST /api/settings/models
    â†’ Store in SQLite local_models
    â†’ Push to gateway via configPatch()
    â†“
Model appears in:
    â†’ Model selector dropdown
    â†’ Direct mode fallback chain
    â†’ Gateway model list
```

### Section 5: Provider Status Dashboard Widget

A persistent widget accessible from the main dashboard header:

**Compact mode (header bar):**
- Small colored dot: green (all good), yellow (issues), red (critical)
- Tooltip: "3/5 providers active"

**Expanded mode (click to expand):**
```
â”Œâ”€ AI Provider Status â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Gateway: ğŸŸ¢ Connected    Mode: Hybrid         â”‚
â”‚                                                â”‚
â”‚  â— Anthropic    ğŸŸ¢ Active   $47.32 remaining  â”‚
â”‚  â— OpenAI       ğŸŸ¢ Active   $12.08 remaining  â”‚
â”‚  â— Google       ğŸŸ¡ Untested  â€”                 â”‚
â”‚  â— Ollama       ğŸŸ¢ Running  llama3.1:70b       â”‚
â”‚  â— xAI          ğŸ”´ Error    Key expired        â”‚
â”‚                                                â”‚
â”‚  [Manage Keys]  [Test All]  [Refresh Credits]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Data source:**
- Reads from `/api/settings/api-keys/batch-status` (cached, refreshed every 60s)
- Gateway status from `/api/openclaw/status`
- Credit data from `/api/settings/credits`

---

## Files to Create/Modify

### New files:
- `src/lib/direct-provider.ts` â€” Direct-to-provider SDK wrappers (Anthropic, OpenAI, Google, Ollama)
- `src/lib/encryption.ts` â€” AES-256-GCM encrypt/decrypt for API keys
- `src/lib/gateway-sync.ts` â€” Push/pull API keys to/from gateway via configPatch()
- `src/components/ui/provider-status-widget.tsx` â€” Header status indicator + expanded widget

### Modified files:
- `src/app/api/settings/api-keys/route.ts` â€” Add test-before-save, encryption, gateway sync
- `src/app/api/settings/api-keys/batch-status/route.ts` â€” Sync ALL_PROVIDERS list
- `src/app/api/settings/credits/route.ts` â€” Add DELETE, add real credit fetch for supported providers
- `src/app/api/settings/models/route.ts` â€” Fix response shape, fix LM Studio health check
- `src/app/api/chat/route.ts` â€” Add direct mode fallback
- `src/app/api/tasks/dispatch/route.ts` â€” Add direct mode fallback
- `src/components/views/settings/ai-api-command-center.tsx` â€” Fix HelpCircle, add Connect pre-populate
- `src/components/views/settings/api-keys-section.tsx` â€” Fix Save & Test, add inline edit
- `src/components/views/settings/ai-model-section.tsx` â€” Fix error handling, show degraded state
- `src/components/views/settings/local-models-section.tsx` â€” Fix Ollama type mismatch, configurable URL
- `src/components/views/settings/settings-types.ts` â€” Add missing provider icons, sync provider lists
- `src/components/views/settings/gateway-section.tsx` â€” Debounce saves, add token toggle
- `src/components/views/settings-panel.tsx` â€” Wire provider status widget

---

## Out of Scope (for now)

- Platform backend (Python) agent orchestrator changes
- Real-time credit polling (background jobs)
- API key rotation / expiry alerts
- Multi-workspace key isolation
- OAuth flows for providers that support them (Google Cloud, Azure AD)
