# MeshGuard Design Partner Candidates

> **Research Date:** January 25, 2026
> **Purpose:** Identify the 5 best design partner candidates for MeshGuard's AI agent governance platform
> **MeshGuard Capabilities:** Identity management, policy enforcement, audit logging, delegation control for autonomous AI agents. Integrates with LangChain, CrewAI, AutoGPT, and custom agent frameworks.

---

## Executive Summary

After extensive research across LangChain case studies, LinkedIn company profiles, engineering blogs, and industry sources, the following 5 companies represent the **strongest design partner candidates** for MeshGuard. They were selected based on:

- **Active multi-agent AI development** using frameworks MeshGuard supports
- **Regulated industry context** requiring governance/compliance
- **Publicly demonstrated AI agent work** with verifiable signals
- **Company stage** (mid-stage startups or innovation teams) â€” accessible for partnership
- **Acute governance pain points** where MeshGuard delivers immediate value

### Priority Ranking

| Rank | Company | Industry | Stack | Employees | Governance Urgency |
|------|---------|----------|-------|-----------|-------------------|
| 1 | Captide | Fintech (Investment Research) | LangChain, LangGraph, LangSmith | 11-50 | ðŸ”´ Critical |
| 2 | Rogo | Fintech (Banking/PE AI) | Custom + multi-model | 51-200 | ðŸ”´ Critical |
| 3 | Remote | HR/Compliance/Payroll | LangChain, LangGraph | 1000+ (AI team ~20-50) | ðŸŸ  High |
| 4 | Monte Carlo | Data + AI Observability | LangGraph, LangSmith, AWS | 200-500 | ðŸŸ  High |
| 5 | Trellix | Cybersecurity | LangGraph, LangSmith, LangGraph Studio | 5000+ (AI team ~20) | ðŸŸ¡ Medium-High |

---

## 1. Captide

### What They Do
Captide is a London-based fintech startup (founded 2024, 11-50 employees) providing agentic AI systems grounded in global corporate disclosures that power leading asset managers, investment banks, and hedge funds. Their domain-specific AI agents analyze structured and unstructured financial data to accelerate equity research, financial modeling, peer benchmarking, corporate events monitoring, M&A transaction analysis, and other high-value investment workflows. They process data from 14,000+ public companies across 44 countries, with agents deployed on LangGraph Platform serving spreadsheet-style parallel invocations across thousands of concurrent cells.

### Why They're Ideal
- **Tiny team in a heavily regulated industry:** 11-50 employees building multi-agent systems for hedge funds and investment banks â€” they can't afford to build governance in-house
- **Multi-agent architecture on LangChain/LangGraph:** Exact stack MeshGuard integrates with
- **Financial regulatory requirements:** Their clients (asset managers, investment banks, hedge funds) are subject to SEC, FCA, and other financial regulatory frameworks requiring audit trails and access controls
- **Explainability is a feature, not a nice-to-have:** They already emphasize "sentence-level traceability for complete transparency and auditability" â€” they understand the need
- **Early-stage and fast-growing:** Founded 2024, recently partnered with Bigdata.com â€” now is the time to embed governance before they scale further

### Their AI Stack
- **Orchestration:** LangGraph Platform (multi-agent, parallel execution)
- **Framework:** LangChain (tool-calling, prompt handling)
- **Monitoring:** LangSmith (tracing, evaluation, cost/accuracy/latency monitoring)
- **UI:** LangGraph Generative UI (React components streamed from agents)
- **Data:** Vector databases, structured financial filings API
- **Models:** Multiple model providers (interchangeable via LangChain)

### Key Person to Contact
- **Primary:** Company founders/CTO (exact names not publicly listed â€” startup is very early-stage)
- **Approach via:** LinkedIn (company page has 479 followers), or through LangChain's community/partnership network since they're a featured LangChain case study
- **LinkedIn:** https://www.linkedin.com/company/captide/

### Pain Point We Solve
Captide's agents access and reason over sensitive financial data for investment decisions at major financial institutions. Their clients (hedge funds, investment banks) require:
- **Agent identity & authorization:** Which agent accessed which corporate filings, and with what permissions?
- **Audit logging:** Complete trace of every agent action touching financial data â€” required for SEC/FCA compliance
- **Delegation control:** When agents spawn parallel tasks across thousands of concurrent cells, who authorized the scope?
- **Policy enforcement:** Agents must not cross information barriers (Chinese walls) between different client portfolios

### Approach Strategy
1. **LangChain Community Introduction:** Captide is a featured LangChain case study. Reach out via LangChain's partner ecosystem or ask for a warm intro from Harrison Chase's team.
2. **Conference Approach:** Look for them at fintech/AI conferences (London FinTech Week, AI in Finance Summit)
3. **Cold LinkedIn:** Small team = founders are approachable. Reference their LangChain blog post specifically.
4. **Email:** Use careers@ or general contact via captide.ai

### Custom Demo Angle
**"Governance for Financial AI Agents"** â€” Demo showing:
- Agent identity management across Captide's parallel agent invocations (thousands of simultaneous spreadsheet cell queries)
- Audit trail showing which agent accessed which corporate filings with timestamps
- Policy rules enforcing information barriers between client portfolios
- Delegation controls ensuring agents only access authorized data sources (e.g., only SEC filings, not internal client data)

### Implementation Plan
1. **Phase 1 (Week 1-2):** Install MeshGuard SDK alongside existing LangChain/LangGraph setup. Map agent identities to their domain-specific agents (Publishing Agent, M&A Agent, etc.)
2. **Phase 2 (Week 3-4):** Configure audit logging to capture every agent tool call and API access to financial filings. Integrate with LangSmith traces for unified observability.
3. **Phase 3 (Week 5-6):** Implement policy enforcement rules â€” data access boundaries per client, rate limiting per agent type, approval workflows for sensitive actions (e.g., accessing non-public filings).
4. **Phase 4 (Week 7-8):** Deploy delegation controls for parallel agent spawning â€” ensure supervisor agents properly scope sub-agent permissions.

### Timeline (Outreach Sequence)
- **Week 1:** Send personalized cold email/LinkedIn message referencing their LangChain case study and specific governance challenges in fintech
- **Week 2:** Follow up with a 2-page "Governance for Financial AI Agents" brief tailored to their architecture
- **Week 3:** Request 30-min call to discuss governance challenges; offer free architecture review
- **Week 4:** Demo MeshGuard with a Captide-specific proof of concept
- **Week 5-6:** Formalize design partnership agreement

### Public Signals
- **LangChain Case Study:** https://www.blog.langchain.com/captide/
- **Website:** https://www.captide.ai/
- **LinkedIn:** https://www.linkedin.com/company/captide/ (479 followers)
- **Partnership with Bigdata.com:** Announced ~Nov 2025, enabling international corporate disclosures access
- **Goldman Sachs earnings analysis:** Published detailed AI-generated earnings analysis, showing production agent usage

---

## 2. Rogo

### What They Do
Rogo (founded 2021, 51-200 employees, New York) is a generative AI platform purpose-built for finance professionals â€” specifically investment bankers and investors. Their AI agents are "trained by the most sophisticated bankers, investors, and AI researchers" to create work outputs across PowerPoint, Excel, and Word. They serve tens of thousands of bankers and investors globally, with millions of queries run in 2025. Rogo deploys to the world's largest financial institutions and has recently launched a Security Advisory Board with four former CISOs collectively bringing 100+ years of security experience.

### Why They're Ideal
- **Explicitly building governance:** They already mention "Admin Governance & Permissions, granular permission controls, role-based access management, comprehensive audit trails, & customizable governance policies" on their website â€” they know they need this
- **Security Advisory Board:** Just launched, with Phil Venables (ex-Google CISO), tsvi gal, Israel Bryski, and Peter Keenan. Their mandate: "help pioneer a set of best practices... as we move further into a new era for finance"
- **Publicly identified the problem:** "We've uncovered a lack of standardization around deploying secure AI" â€” this is MeshGuard's exact thesis
- **Enterprise financial clients:** SOC2, ISO 27001, CCPA, GDPR certified â€” their clients demand governance
- **Right stage:** 51-200 employees, growing fast, deploying to major institutions â€” needs governance infrastructure NOW

### Their AI Stack
- **Models:** Custom-trained financial reasoning models, multi-model architecture
- **Deployment:** Single tenant deployments for security-conscious firms
- **Security:** SOC2, ISO 27001, CCPA, GDPR, end-to-end encryption
- **Output:** PowerPoint, Excel, Word generation via AI agents
- **Infrastructure:** Cloud-based with zero-trust principles, automated security tooling

### Key Person to Contact
- **Julia Lauer** â€” Key executive (appears in leadership posts on LinkedIn, posted about 2025 learnings and 2026 vision)
  - LinkedIn: https://www.linkedin.com/in/julia-lauer-423834137
- **Phil Venables** â€” Security Advisory Board (ex-Google CISO)
  - LinkedIn: https://www.linkedin.com/in/philvenables
- **Sales contact:** sales@rogo.ai

### Pain Point We Solve
Rogo's agents operate autonomously within the most security-sensitive financial institutions. They face:
- **Standardization gap:** They've publicly stated "a lack of standardization around deploying secure AI" â€” MeshGuard IS that standard
- **Multi-tenant governance:** Different financial institutions need different policy rules, access controls, and audit requirements
- **Agent delegation:** Their agents create financial work products (models, presentations, reports) â€” need to track which agent created what, with what data, for which client
- **Regulatory compliance:** SEC, FINRA, and other regulatory frameworks require complete audit trails for any AI-generated financial analysis

### Approach Strategy
1. **Security Advisory Board connection:** Phil Venables (ex-Google CISO) is on their board. Reach out through security/governance community connections.
2. **Direct email:** sales@rogo.ai â€” frame as a governance infrastructure partnership, not a sales pitch
3. **Conference approach:** Rogo hosts events (Women in Finance, etc.) â€” attend and network
4. **LinkedIn:** Julia Lauer actively posts about partnership and enterprise deployment challenges â€” she's the right entry point

### Custom Demo Angle
**"The Governance Standard for Financial AI"** â€” Demo showing:
- Standardized governance framework that Rogo can offer to ALL their financial institution clients out of the box
- Multi-tenant policy enforcement (different rules per institution)
- Audit trail that satisfies SEC/FINRA requirements for AI-generated financial analysis
- Agent identity management tracking which AI agent generated which financial document

### Implementation Plan
1. **Phase 1 (Week 1-2):** Integration scoping â€” understand Rogo's agent architecture, identify governance hooks in their existing infrastructure
2. **Phase 2 (Week 3-4):** Deploy MeshGuard agent identity layer â€” assign identities to each of Rogo's agent types (research agent, Excel agent, PowerPoint agent)
3. **Phase 3 (Week 5-6):** Implement audit logging that captures every agent action, data access, and output generation with institution-level attribution
4. **Phase 4 (Week 7-8):** Build policy enforcement templates for different regulatory frameworks (SEC, FCA, FINRA) that Rogo can deploy per-institution

### Timeline (Outreach Sequence)
- **Week 1:** Email Julia Lauer referencing their Security Advisory Board announcement and "standardization" challenge
- **Week 2:** Follow up with a brief: "MeshGuard: The Governance Standard for Financial AI Agents"
- **Week 3:** Request intro to Phil Venables or Security Advisory Board for governance partnership discussion
- **Week 4:** Joint call with Rogo's engineering and security teams â€” present architecture integration
- **Week 5-6:** Pilot agreement with specific governance requirements from one of their banking clients

### Public Signals
- **Website:** https://rogo.ai/ â€” explicitly lists "Admin Governance & Permissions" and "comprehensive audit trails"
- **Security Advisory Board:** https://rogo.ai/security-council â€” launched Jan 2026
- **LinkedIn:** https://www.linkedin.com/company/rogoai/ (16,859 followers)
- **Julia Lauer's post (Jan 2026):** "Rogo is now in the hands of tens of thousands of bankers and investors globally... deploying at scale requires deploying with humility"
- **Security certifications:** SOC2, ISO 27001, CCPA, GDPR
- **Contact:** sales@rogo.ai

---

## 3. Remote

### What They Do
Remote (founded ~2019, 1000+ employees) is a fast-growing global HR platform that helps companies hire, manage, and pay employees across 190+ countries. They handle employee onboarding, payroll processing, and compliance across dozens of regulatory environments. Remote built a sophisticated Code Execution Agent using LangChain and LangGraph to automate complex data migrations â€” processing thousands of spreadsheets and SQL exports for customer onboarding. They also maintain an open-source Remote AI Agent Toolkit for partner integrations. Co-founders: Job van der Voort (CEO) and Marcelo Lebre (President).

### Why They're Ideal
- **Multi-jurisdiction compliance:** Operates across 190+ countries with different employment laws, tax regulations, and data protection rules â€” compliance is existential
- **AI agents handling sensitive data:** Their Code Execution Agent processes payroll data, employee PII, and compliance documents â€” the most sensitive data categories
- **LangChain/LangGraph stack:** Exact frameworks MeshGuard integrates with
- **Open-source AI toolkit:** They publish the Remote AI Agent Toolkit for partners, meaning they think about AI governance in an ecosystem context
- **"Accuracy and compliance are non-negotiable":** Direct quote from their case study â€” they take governance seriously
- **Growing AI team:** SVP Frontier (Pedro Barros) leads AI initiatives; Staff Engineer JosÃ© Mussa building agent systems

### Their AI Stack
- **Orchestration:** LangGraph (node-and-edge model for workflow state management)
- **Framework:** LangChain (tool-calling, prompt handling, model provider abstraction)
- **Execution:** Python sandboxed execution in WebAssembly (Pandas for data manipulation)
- **Models:** GPT-5 and other providers via LangChain abstraction
- **Data:** Secure storage for customer HR/payroll data uploads (CSV, Excel, SQL)
- **Open Source:** Remote AI Agent Toolkit (LangChain-based)

### Key Person to Contact
- **Pedro Barros** â€” SVP Frontier (leads AI/innovation at Remote)
  - LinkedIn: https://www.linkedin.com/in/pedrobarros (search "Pedro Barros Remote SVP Frontier")
- **JosÃ© Mussa** â€” Staff Software Engineer (author of LangChain case study, builds the Code Execution Agent)
  - LinkedIn: search "JosÃ© Mussa Remote Staff Software Engineer"
- **Job van der Voort** â€” CEO/Co-founder
- **Marcelo Lebre** â€” President/Co-founder

### Pain Point We Solve
Remote's Code Execution Agent processes the most sensitive data possible â€” employee PII, payroll information, and compliance documents â€” across dozens of regulatory jurisdictions:
- **Data access governance:** Which agent accessed which customer's payroll data? Who authorized it?
- **Jurisdictional policy enforcement:** An agent processing EU employee data must follow GDPR rules; US data must follow different rules â€” policies must vary by jurisdiction
- **Delegation control:** The agent iteratively writes and executes code in a sandbox â€” each step needs authorization tracking
- **Audit trail for regulators:** Employment regulators in 190+ countries may require proof of how employee data was processed

### Approach Strategy
1. **LangChain community warm intro:** Remote is a featured LangChain case study â€” LangChain team can make an introduction
2. **Open source contribution:** Contribute governance utilities to the Remote AI Agent Toolkit, opening a conversation
3. **Pedro Barros direct outreach:** SVP Frontier is the decision-maker for AI infrastructure investments
4. **Conference approach:** Remote is active at HR Tech, Web Summit, and AI conferences

### Custom Demo Angle
**"Governance for Global HR AI Agents"** â€” Demo showing:
- Jurisdictional policy enforcement: Agent processing German employee data automatically follows GDPR data minimization rules; agent processing US data follows CCPA rules
- Audit trail tracking every agent action in the data migration pipeline (file ingestion â†’ reasoning â†’ code execution â†’ validation)
- Identity management for the Code Execution Agent and its iterative sub-processes
- Delegation controls ensuring agents can only access data for the specific customer being onboarded

### Implementation Plan
1. **Phase 1 (Week 1-2):** Integrate MeshGuard SDK into Remote's AI Service, alongside existing LangChain setup. Map the Code Execution Agent pipeline to MeshGuard's identity and policy framework.
2. **Phase 2 (Week 3-4):** Configure jurisdiction-aware policy enforcement (GDPR, CCPA, etc.) that automatically applies based on employee/customer location data.
3. **Phase 3 (Week 5-6):** Implement comprehensive audit logging for every step in the agent pipeline â€” file access, code generation, code execution, validation.
4. **Phase 4 (Week 7-8):** Extend to Remote AI Agent Toolkit, enabling partner integrations to also benefit from governance.

### Timeline (Outreach Sequence)
- **Week 1:** Email Pedro Barros referencing the LangChain case study and governance challenges for multi-jurisdiction AI agents
- **Week 2:** Send a brief: "Governance for AI Agents Processing Global Employee Data"
- **Week 3:** Request 30-min call; offer a free governance architecture review
- **Week 4:** Demo with Remote's AI team (JosÃ© Mussa and team)
- **Week 5-6:** Pilot focused on GDPR compliance for EU employee data migration agents

### Public Signals
- **LangChain Case Study:** https://www.blog.langchain.com/customers-remote/
- **Website:** https://remote.com/
- **About page with leadership:** https://remote.com/about
- **Open-source AI Toolkit:** Referenced in case study (LangChain-based)
- **Blog:** https://remote.com/blog â€” active with compliance content (EU Pay Transparency Directive, etc.)
- **Recent acquisition of Atlas:** Expanding compliance footprint
- **LinkedIn:** https://www.linkedin.com/company/remote-com/

---

## 4. Monte Carlo

### What They Do
Monte Carlo (founded ~2019, estimated 200-500 employees, San Francisco) is the leading data + AI observability platform for enterprises. They help organizations monitor data and AI reliability issues and trace them to root causes. Their flagship AI product is a Troubleshooting Agent built on LangGraph that can **launch hundreds of sub-agents simultaneously** to investigate data quality issues â€” checking code changes, analyzing timelines, investigating dependencies, and exploring multiple root cause hypotheses in parallel. Their customers are large enterprises where data drives significant revenue. Product Manager Bryce Heltzel leads agent development.

### Why They're Ideal
- **Hundreds of concurrent sub-agents:** Their architecture spawns hundreds of sub-agents per investigation â€” a governance nightmare without proper controls
- **Enterprise customers who demand governance:** They serve large enterprises where "data that remains incorrect or unavailable can affect millions of dollars of business"
- **Already thinking about observability:** As a data observability company, they inherently understand the value of monitoring and audit logging â€” MeshGuard extends this to agent governance
- **LangGraph stack:** Exact framework MeshGuard integrates with
- **Trust and validation focus:** Currently focused on "visibility and validation â€” understanding where bugs occur in their traces and building robust feedback mechanisms"
- **Fast-moving team:** Built their agent in 4 weeks for industry summits â€” willing to adopt new tools quickly

### Their AI Stack
- **Orchestration:** LangGraph (graph-based decision flow, dynamic sub-agent spawning)
- **Monitoring:** LangSmith (tracing, debugging, day-one integration)
- **Infrastructure:** AWS â€” ECS Fargate (containerized microservices), Amazon Bedrock (foundation models), Amazon RDS (data), Network Load Balancer
- **Architecture:** Auth Gateway Lambda + Monolith Service (GraphQL/REST) + AI Agent Service
- **Models:** Amazon Bedrock foundation models

### Key Person to Contact
- **Bryce Heltzel** â€” Product Manager (leads AI Troubleshooting Agent, deeply involved in prompt engineering, authored LangChain case study)
  - LinkedIn: search "Bryce Heltzel Monte Carlo"
- **Co-founders:** Barr Moses (CEO) and Lior Gavish (CTO) â€” well-known in the data engineering community
  - LinkedIn: https://www.linkedin.com/in/barrmoses/ , https://www.linkedin.com/in/liorgavish/

### Pain Point We Solve
Monte Carlo's Troubleshooting Agent spawns hundreds of concurrent sub-agents that access customer data infrastructure. This creates governance challenges:
- **Sub-agent identity & authorization:** When 100+ sub-agents spawn simultaneously, which one has access to which customer's data pipelines?
- **Delegation control:** The parent agent delegates investigation tasks to sub-agents â€” need to ensure proper scope and permissions cascade
- **Audit trail for enterprise clients:** Large enterprises need proof that AI agents investigating their data followed proper access protocols
- **Policy enforcement:** Agents checking code changes, accessing production databases, and modifying alerts need tiered permission levels

### Approach Strategy
1. **Data engineering community:** Monte Carlo's founders (Barr Moses, Lior Gavish) are prominent in the data engineering community â€” approach via dbt community, Data Council, or data engineering Slack groups
2. **Bryce Heltzel direct outreach:** As Product Manager leading the agent product, he's the ideal first contact
3. **LangChain community:** Monte Carlo is a featured case study â€” warm intro via LangChain
4. **Conference approach:** Data Council, Snowflake Summit, dbt Coalesce

### Custom Demo Angle
**"Governance for Multi-Agent Data Investigation"** â€” Demo showing:
- Identity management for hundreds of simultaneously spawned sub-agents
- Delegation controls cascading from parent Troubleshooting Agent to sub-agents, with proper scope limitation
- Audit trail capturing every sub-agent's investigation path (code changes checked, databases accessed, hypotheses explored)
- Policy enforcement ensuring sub-agents only access customer data they're authorized to investigate

### Implementation Plan
1. **Phase 1 (Week 1-2):** Integrate MeshGuard SDK into Monte Carlo's AI Agent Service on ECS Fargate. Map parent agent â†’ sub-agent delegation hierarchy.
2. **Phase 2 (Week 3-4):** Configure identity management for dynamic sub-agent spawning â€” each sub-agent gets a scoped identity with inherited-but-limited permissions.
3. **Phase 3 (Week 5-6):** Implement audit logging capturing the full investigation graph â€” every sub-agent's actions, data accesses, and findings.
4. **Phase 4 (Week 7-8):** Build policy enforcement rules per enterprise customer â€” ensuring Monte Carlo's agents respect customer-specific data access boundaries.

### Timeline (Outreach Sequence)
- **Week 1:** Email Bryce Heltzel referencing their LangChain case study and multi-agent governance challenges
- **Week 2:** Share brief: "Governance for Dynamic Multi-Agent Investigation Systems"
- **Week 3:** Request 30-min call; reference their "visibility and validation" focus as aligned with MeshGuard's mission
- **Week 4:** Demo with Monte Carlo's AI team
- **Week 5-6:** Pilot focused on delegation controls for their Troubleshooting Agent sub-agent spawning

### Public Signals
- **LangChain Case Study:** https://www.blog.langchain.com/customers-monte-carlo/
- **Website:** https://www.montecarlodata.com/
- **Agent Observability page:** https://www.montecarlodata.com/platform/observability-agents
- **Forrester TEI Report:** Published economic impact study â€” enterprise-validated
- **LinkedIn:** https://www.linkedin.com/company/monte-carlo-data/
- **Barr Moses** is a prominent speaker on data quality and AI observability

---

## 5. Trellix

### What They Do
Trellix is a leading cybersecurity firm with 40,000+ customers focused on preventing organizations from cybersecurity attacks and threats. Their Professional Services Team built "Sidekick," an agentic platform using LangGraph and LangSmith that automates cybersecurity integration tasks and log parsing. Sidekick generates parsers for unknown log formats (reducing parsing time from days to minutes), writes cybersecurity plugins and integrations, and is being expanded to external partners. Their engineering team uses LangGraph Studio for workflow visualization, LangSmith for experimentation and performance monitoring, and a modular subgraph architecture.

### Why They're Ideal
- **Security-critical industry:** Cybersecurity agents handling threat data, customer logs, and security integrations MUST have governance
- **Expanding agents to external partners:** They plan to "expand the capabilities of Sidekick to external partners" â€” governance is essential before this happens
- **Innovation team building on LangGraph:** Their Professional Services Team is the right size and autonomy level for a design partnership
- **Existing observability mindset:** Already using LangSmith for traces, experiments, and metrics â€” they understand monitoring
- **Compliance requirements:** SOC2, FedRAMP, and other security certifications demand audit trails
- **Human-in-the-loop needs:** Already using LangGraph's human-in-the-loop to approve/rewind agent actions â€” MeshGuard formalizes this

### Their AI Stack
- **Orchestration:** LangGraph (Send API, subgraph calling, map-reduce style graphs)
- **Framework:** LangChain (tool-calling, model interaction)
- **Monitoring:** LangSmith (traces, experiments, datasets, latency monitoring)
- **Visualization:** LangGraph Studio (workflow visualization for stakeholders)
- **Architecture:** Modular subgraphs composed into larger graphs, human-in-the-loop checkpoints
- **Infrastructure:** AWS (referenced in debugging context)

### Key Person to Contact
- **AI Engineering Team Lead / Professional Services Team** â€” exact name not publicly listed
- **Approach via:** Trellix's Professional Services team, or via LangChain's enterprise customer network
- **LinkedIn:** https://www.linkedin.com/company/traborlabs/ (Trellix corporate page)
- **General contact:** Through trellix.com sales/partnership channels

### Pain Point We Solve
Trellix's Sidekick agents parse security logs, write cybersecurity integrations, and generate code â€” all in a security-critical context:
- **Agent authorization:** Which Sidekick agent is authorized to parse which customer's security logs?
- **Audit trail for security operations:** Complete trace of every agent action touching threat data â€” required for SOC2, FedRAMP
- **Policy enforcement for code generation:** Agents writing security plugins must follow strict coding standards and not introduce vulnerabilities
- **Delegation to external partners:** When expanding Sidekick to external partners, need governance for third-party agent interactions

### Approach Strategy
1. **LangChain community:** Trellix is a featured case study â€” warm intro via LangChain team
2. **Cybersecurity conferences:** RSA Conference, Black Hat, DEF CON â€” Trellix has a major presence
3. **Professional Services outreach:** Target the team that built Sidekick specifically
4. **Security-first messaging:** Frame MeshGuard as a cybersecurity-grade governance layer

### Custom Demo Angle
**"Security-Grade Governance for Cybersecurity AI Agents"** â€” Demo showing:
- Agent identity and authorization for Sidekick sub-agents (parsing agents, plugin-writing agents, etc.)
- Audit trail satisfying SOC2/FedRAMP requirements for AI-generated security artifacts
- Policy enforcement preventing agents from accessing customer data beyond their assigned scope
- Human-in-the-loop approval workflows formalized as governance policies (not ad-hoc)

### Implementation Plan
1. **Phase 1 (Week 1-2):** Integrate MeshGuard SDK into Sidekick's LangGraph architecture. Map subgraph identities and permissions.
2. **Phase 2 (Week 3-4):** Configure audit logging for every agent action â€” log parsing events, code generation, API documentation access.
3. **Phase 3 (Week 5-6):** Implement policy enforcement â€” ensure agents only access logs from assigned customers, generated code follows security standards.
4. **Phase 4 (Week 7-8):** Build governance framework for external partner expansion â€” third-party agent identity verification and scoped permissions.

### Timeline (Outreach Sequence)
- **Week 1:** Email through LangChain network or Trellix Professional Services, referencing their case study
- **Week 2:** Send brief: "Governance for Cybersecurity AI Agents â€” From Internal Sidekick to External Partner Platform"
- **Week 3:** Request meeting with Sidekick engineering team; offer governance architecture review
- **Week 4:** Demo MeshGuard with cybersecurity-specific use case
- **Week 6-8:** Pilot focused on audit logging and partner expansion governance

### Public Signals
- **LangChain Case Study:** https://www.blog.langchain.com/customers-trellix/
- **Website:** https://www.trellix.com/
- **Sidekick platform:** Internal agentic platform, expanding to external partners
- **Key metrics from case study:** Reduced log parsing from days to minutes, accelerated customer request resolution
- **LangGraph Studio usage:** Used to visualize agent workflows for non-technical stakeholders
- **LangSmith adoption:** Day-one integration for debugging and performance monitoring

---

## Cross-Cutting Themes & MeshGuard Positioning

### Common Pain Points Across All 5 Candidates

1. **Agent Identity:** All 5 companies deploy multiple specialized agents. None have standardized identity management across agents.
2. **Audit Logging:** All operate in regulated contexts (finance, HR, cybersecurity, enterprise data) where complete audit trails are required.
3. **Delegation Control:** 3 of 5 (Captide, Monte Carlo, Trellix) use multi-agent architectures with sub-agent spawning â€” delegation governance is a critical gap.
4. **Policy Enforcement:** All need differentiated access controls (per-customer, per-jurisdiction, per-data-classification) but are building ad-hoc solutions.
5. **LangChain/LangGraph Stack:** 4 of 5 use LangChain/LangGraph, making MeshGuard integration straightforward.

### Recommended Outreach Priority

| Priority | Company | Reason |
|----------|---------|--------|
| ðŸ¥‡ Highest | **Captide** | Smallest team, most acute need, exact stack match, earliest stage = highest partnership willingness |
| ðŸ¥ˆ High | **Rogo** | Already building governance, publicly identified the problem, Security Advisory Board = warm reception |
| ðŸ¥‰ High | **Remote** | LangChain stack, compliance-first culture, open-source mindset = natural partner |
| 4th | **Monte Carlo** | Hundreds of sub-agents = unique governance challenge, observability DNA |
| 5th | **Trellix** | Larger company but innovation team is accessible, cybersecurity = governance-native |

### Conference Calendar for In-Person Outreach
- **LangChain community events** â€” All 4 LangChain customers could be reached here
- **London FinTech Week** (for Captide)
- **AI in Finance Summit** (for Captide, Rogo, Hebbia)
- **RSA Conference / Black Hat** (for Trellix)
- **Data Council** (for Monte Carlo)
- **Web Summit / HR Tech** (for Remote)

---

*Research compiled from: LangChain Blog case studies, LinkedIn company profiles, company websites, product documentation, and industry sources. All information is publicly available as of January 2026.*
