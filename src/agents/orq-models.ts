import type { ModelDefinitionConfig } from "../config/types.js";

export const ORQ_BASE_URL = "https://api.orq.ai/v2/router";
export const ORQ_DEFAULT_MODEL_ID = "openai/gpt-5.2";
export const ORQ_DEFAULT_MODEL_REF = `orq/${ORQ_DEFAULT_MODEL_ID}`;

const ORQ_MODEL_CATALOG: Array<{
  id: string;
  name: string;
  reasoning: boolean;
  input: Array<"text" | "image">;
  cost: ModelDefinitionConfig["cost"];
  contextWindow: number;
  maxTokens: number;
}> = [
  {
    id: "anthropic/claude-opus-4-5-20251101",
    name: "Claude Opus 4.5",
    reasoning: false,
    input: ["text", "image"],
    cost: { input: 5, output: 25, cacheRead: 0.5, cacheWrite: 6.25 },
    contextWindow: 200000,
    maxTokens: 64000,
  },
  {
    id: "anthropic/claude-sonnet-4-5-20250929",
    name: "Claude Sonnet 4.5",
    reasoning: false,
    input: ["text", "image"],
    cost: { input: 3, output: 15, cacheRead: 0.3, cacheWrite: 3.75 },
    contextWindow: 200000,
    maxTokens: 64000,
  },
  {
    id: "anthropic/claude-haiku-4-5-20251001",
    name: "Claude Haiku 4.5",
    reasoning: false,
    input: ["text", "image"],
    cost: { input: 1, output: 5, cacheRead: 0.1, cacheWrite: 1.25 },
    contextWindow: 200000,
    maxTokens: 64000,
  },
  {
    id: "google-ai/gemini-2.5-pro",
    name: "Gemini 2.5 Pro",
    reasoning: true,
    input: ["text", "image"],
    cost: { input: 1.25, output: 10, cacheRead: 0.125, cacheWrite: 0 },
    contextWindow: 1048576,
    maxTokens: 65536,
  },
  {
    id: "google-ai/gemini-2.5-flash",
    name: "Gemini 2.5 Flash",
    reasoning: true,
    input: ["text", "image"],
    cost: { input: 0.3, output: 2.5, cacheRead: 0.03, cacheWrite: 0 },
    contextWindow: 1048576,
    maxTokens: 65536,
  },
  {
    id: "google/gemini-2.5-pro",
    name: "Gemini 2.5 Pro (Vertex AI)",
    reasoning: true,
    input: ["text", "image"],
    cost: { input: 1.25, output: 10, cacheRead: 0.125, cacheWrite: 0 },
    contextWindow: 1048576,
    maxTokens: 65536,
  },
  {
    id: "google/gemini-2.5-flash",
    name: "Gemini 2.5 Flash (Vertex AI)",
    reasoning: true,
    input: ["text", "image"],
    cost: { input: 0.3, output: 2.5, cacheRead: 0.03, cacheWrite: 0 },
    contextWindow: 1048576,
    maxTokens: 65536,
  },
  {
    id: "google-ai/gemini-3-pro-preview",
    name: "Gemini 3 Pro Preview",
    reasoning: true,
    input: ["text", "image"],
    cost: { input: 2, output: 12, cacheRead: 0, cacheWrite: 0 },
    contextWindow: 1000000,
    maxTokens: 65535,
  },
  {
    id: "google-ai/gemini-3-flash-preview",
    name: "Gemini 3 Flash Preview",
    reasoning: true,
    input: ["text", "image"],
    cost: { input: 0.5, output: 3, cacheRead: 0, cacheWrite: 0 },
    contextWindow: 1048576,
    maxTokens: 65535,
  },
  {
    id: "google/gemini-3-pro-preview",
    name: "Gemini 3 Pro Preview (Vertex AI)",
    reasoning: true,
    input: ["text", "image"],
    cost: { input: 2, output: 12, cacheRead: 0, cacheWrite: 0 },
    contextWindow: 1048576,
    maxTokens: 65535,
  },
  {
    id: "google/gemini-3-flash-preview",
    name: "Gemini 3 Flash Preview (Vertex AI)",
    reasoning: true,
    input: ["text", "image"],
    cost: { input: 0.5, output: 3, cacheRead: 0, cacheWrite: 0 },
    contextWindow: 1048576,
    maxTokens: 65535,
  },
  {
    id: "openai/gpt-5",
    name: "GPT-5",
    reasoning: true,
    input: ["text", "image"],
    cost: { input: 1.25, output: 10, cacheRead: 0, cacheWrite: 0 },
    contextWindow: 400000,
    maxTokens: 128000,
  },
  {
    id: "openai/gpt-5-mini",
    name: "GPT-5 Mini",
    reasoning: true,
    input: ["text", "image"],
    cost: { input: 0.25, output: 2, cacheRead: 0.025, cacheWrite: 0 },
    contextWindow: 400000,
    maxTokens: 128000,
  },
  {
    id: "openai/gpt-5-nano",
    name: "GPT-5 Nano",
    reasoning: true,
    input: ["text", "image"],
    cost: { input: 0.05, output: 0.4, cacheRead: 0, cacheWrite: 0 },
    contextWindow: 400000,
    maxTokens: 128000,
  },
  {
    id: "openai/gpt-5.2",
    name: "GPT-5.2",
    reasoning: true,
    input: ["text", "image"],
    cost: { input: 1.75, output: 14, cacheRead: 0.175, cacheWrite: 0 },
    contextWindow: 400000,
    maxTokens: 128000,
  },
  {
    id: "groq/llama-3.1-8b-instant",
    name: "Llama 3.1 8B Instant",
    reasoning: false,
    input: ["text"],
    cost: { input: 0.05, output: 0.08, cacheRead: 0, cacheWrite: 0 },
    contextWindow: 131072,
    maxTokens: 131072,
  },
  {
    id: "groq/llama-3.3-70b-versatile",
    name: "Llama 3.3 70B Versatile",
    reasoning: false,
    input: ["text"],
    cost: { input: 0.59, output: 0.79, cacheRead: 0, cacheWrite: 0 },
    contextWindow: 131072,
    maxTokens: 32768,
  },
  {
    id: "groq/meta-llama/llama-4-maverick-17b-128e-instruct",
    name: "Llama 4 Maverick 17B 128E Instruct",
    reasoning: false,
    input: ["text"],
    cost: { input: 0.2, output: 0.6, cacheRead: 0, cacheWrite: 0 },
    contextWindow: 131072,
    maxTokens: 131072,
  },
  {
    id: "groq/meta-llama/llama-4-scout-17b-16e-instruct",
    name: "Llama 4 Scout 17B 16E Instruct",
    reasoning: false,
    input: ["text"],
    cost: { input: 0.11, output: 0.34, cacheRead: 0, cacheWrite: 0 },
    contextWindow: 8192,
    maxTokens: 8192,
  },
  {
    id: "groq/meta-llama/llama-guard-4-12b",
    name: "Llama Guard 4 12B",
    reasoning: false,
    input: ["text"],
    cost: { input: 0.2, output: 0.2, cacheRead: 0, cacheWrite: 0 },
    contextWindow: 1024,
    maxTokens: 1024,
  },
  {
    id: "groq/meta-llama/llama-prompt-guard-2-86m",
    name: "Llama Prompt Guard 2 86M",
    reasoning: false,
    input: ["text"],
    cost: { input: 0.04, output: 0.04, cacheRead: 0, cacheWrite: 0 },
    contextWindow: 512,
    maxTokens: 512,
  },
  {
    id: "groq/moonshotai/kimi-k2-instruct",
    name: "Kimi K2 Instruct",
    reasoning: false,
    input: ["text"],
    cost: { input: 1, output: 3, cacheRead: 0, cacheWrite: 0 },
    contextWindow: 16384,
    maxTokens: 16384,
  },
  {
    id: "groq/moonshotai/kimi-k2-instruct-0905",
    name: "Kimi K2 Instruct 0905",
    reasoning: false,
    input: ["text"],
    cost: { input: 1, output: 3, cacheRead: 0, cacheWrite: 0 },
    contextWindow: 16384,
    maxTokens: 16384,
  },
  {
    id: "groq/openai/gpt-oss-120b",
    name: "GPT OSS 120B (Groq)",
    reasoning: true,
    input: ["text"],
    cost: { input: 0.15, output: 0.6, cacheRead: 0, cacheWrite: 0 },
    contextWindow: 131072,
    maxTokens: 65536,
  },
  {
    id: "groq/openai/gpt-oss-20b",
    name: "GPT OSS 20B (Groq)",
    reasoning: true,
    input: ["text"],
    cost: { input: 0.075, output: 0.3, cacheRead: 0, cacheWrite: 0 },
    contextWindow: 131072,
    maxTokens: 65536,
  },
  {
    id: "groq/qwen/qwen3-32b",
    name: "Qwen 3 32B (Groq)",
    reasoning: true,
    input: ["text"],
    cost: { input: 0.29, output: 0.59, cacheRead: 0, cacheWrite: 0 },
    contextWindow: 131072,
    maxTokens: 16384,
  },
  {
    id: "cerebras/gpt-oss-120b",
    name: "GPT OSS 120B (Cerebras)",
    reasoning: true,
    input: ["text"],
    cost: { input: 0.25, output: 0.69, cacheRead: 0, cacheWrite: 0 },
    contextWindow: 131072,
    maxTokens: 8192,
  },
  {
    id: "cerebras/llama-3.3-70b",
    name: "Llama 3.3 70B (Cerebras)",
    reasoning: false,
    input: ["text"],
    cost: { input: 0.85, output: 1.2, cacheRead: 0, cacheWrite: 0 },
    contextWindow: 128000,
    maxTokens: 8192,
  },
  {
    id: "cerebras/llama3.1-8b",
    name: "Llama 3.1 8B (Cerebras)",
    reasoning: false,
    input: ["text"],
    cost: { input: 0.1, output: 0.1, cacheRead: 0, cacheWrite: 0 },
    contextWindow: 8192,
    maxTokens: 8192,
  },
  {
    id: "cerebras/qwen-3-235b-a22b-instruct-2507",
    name: "Qwen 3 235B A22B Instruct 2507 (Cerebras)",
    reasoning: false,
    input: ["text"],
    cost: { input: 0.6, output: 1.2, cacheRead: 0, cacheWrite: 0 },
    contextWindow: 8192,
    maxTokens: 8192,
  },
  {
    id: "cerebras/qwen-3-32b",
    name: "Qwen 3 32B (Cerebras)",
    reasoning: false,
    input: ["text"],
    cost: { input: 0.6, output: 0.6, cacheRead: 0, cacheWrite: 0 },
    contextWindow: 128000,
    maxTokens: 8192,
  },
];

export function buildOrqModelDefinitions(): ModelDefinitionConfig[] {
  return ORQ_MODEL_CATALOG.map((model) => ({
    id: model.id,
    name: model.name,
    reasoning: model.reasoning,
    input: [...model.input],
    cost: model.cost,
    contextWindow: model.contextWindow,
    maxTokens: model.maxTokens,
  }));
}
