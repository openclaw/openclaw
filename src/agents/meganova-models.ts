import type { ModelDefinitionConfig } from "../config/types.models.js";

export const MEGANOVA_BASE_URL = "https://api.meganova.ai/v1";

export const MEGANOVA_MODEL_CATALOG: ModelDefinitionConfig[] = [
  // --- Frontier models ---
  {
    id: "anthropic/claude-opus-4-6",
    name: "Claude Opus 4.6",
    reasoning: false,
    input: ["text", "image"],
    contextWindow: 1000000,
    maxTokens: 32768,
    cost: { input: 4.0, output: 20.0, cacheRead: 4.0, cacheWrite: 20.0 },
  },
  {
    id: "anthropic/claude-opus-4-5-20251101",
    name: "Claude Opus 4.5",
    reasoning: false,
    input: ["text", "image"],
    contextWindow: 200000,
    maxTokens: 32768,
    cost: { input: 4.0, output: 20.0, cacheRead: 4.0, cacheWrite: 20.0 },
  },
  {
    id: "anthropic/claude-sonnet-4-5-20250929",
    name: "Claude Sonnet 4.5",
    reasoning: false,
    input: ["text", "image"],
    contextWindow: 1000000,
    maxTokens: 32768,
    cost: { input: 2.4, output: 12.0, cacheRead: 2.4, cacheWrite: 12.0 },
  },
  {
    id: "anthropic/claude-haiku-4-5-20251001",
    name: "Claude Haiku 4.5",
    reasoning: false,
    input: ["text", "image"],
    contextWindow: 200000,
    maxTokens: 32768,
    cost: { input: 0.8, output: 4.0, cacheRead: 0.8, cacheWrite: 4.0 },
  },
  {
    id: "anthropic/claude-opus-4-20250514",
    name: "Claude Opus 4",
    reasoning: false,
    input: ["text", "image"],
    contextWindow: 200000,
    maxTokens: 32768,
    cost: { input: 12.0, output: 60.0, cacheRead: 12.0, cacheWrite: 60.0 },
  },
  {
    id: "openai/gpt-5.2",
    name: "GPT-5.2",
    reasoning: false,
    input: ["text", "image"],
    contextWindow: 400000,
    maxTokens: 32768,
    cost: { input: 1.4, output: 11.2, cacheRead: 1.4, cacheWrite: 11.2 },
  },
  {
    id: "openai/gpt-5.1",
    name: "GPT-5.1",
    reasoning: false,
    input: ["text", "image"],
    contextWindow: 400000,
    maxTokens: 32768,
    cost: { input: 1.0, output: 8.0, cacheRead: 1.0, cacheWrite: 8.0 },
  },
  {
    id: "openai/gpt-5",
    name: "GPT-5",
    reasoning: false,
    input: ["text", "image"],
    contextWindow: 400000,
    maxTokens: 32768,
    cost: { input: 1.0, output: 8.0, cacheRead: 1.0, cacheWrite: 8.0 },
  },
  {
    id: "openai/gpt-5-mini",
    name: "GPT-5 Mini",
    reasoning: false,
    input: ["text", "image"],
    contextWindow: 400000,
    maxTokens: 32768,
    cost: { input: 0.2, output: 1.6, cacheRead: 0.2, cacheWrite: 1.6 },
  },
  {
    id: "openai/gpt-5-nano",
    name: "GPT-5 Nano",
    reasoning: false,
    input: ["text", "image"],
    contextWindow: 400000,
    maxTokens: 16384,
    cost: { input: 0.04, output: 0.32, cacheRead: 0.04, cacheWrite: 0.32 },
  },
  {
    id: "openai/gpt-4o-mini",
    name: "GPT-4o Mini",
    reasoning: false,
    input: ["text", "image"],
    contextWindow: 128000,
    maxTokens: 16384,
    cost: { input: 0.4, output: 1.6, cacheRead: 0.4, cacheWrite: 1.6 },
  },
  {
    id: "openai/gpt-4-turbo",
    name: "GPT-4 Turbo",
    reasoning: false,
    input: ["text", "image"],
    contextWindow: 128000,
    maxTokens: 4096,
    cost: { input: 8.0, output: 24.0, cacheRead: 8.0, cacheWrite: 24.0 },
  },
  {
    id: "gemini/gemini-3-pro-preview",
    name: "Gemini 3 Pro Preview",
    reasoning: false,
    input: ["text", "image"],
    contextWindow: 1048576,
    maxTokens: 65536,
    cost: { input: 1.6, output: 9.6, cacheRead: 1.6, cacheWrite: 9.6 },
  },
  {
    id: "gemini/gemini-3-flash-preview",
    name: "Gemini 3 Flash Preview",
    reasoning: false,
    input: ["text", "image"],
    contextWindow: 1048576,
    maxTokens: 65536,
    cost: { input: 0.4, output: 2.4, cacheRead: 0.4, cacheWrite: 2.4 },
  },
  {
    id: "gemini/gemini-2.5-pro",
    name: "Gemini 2.5 Pro",
    reasoning: false,
    input: ["text", "image"],
    contextWindow: 1048576,
    maxTokens: 65536,
    cost: { input: 1.0, output: 8.0, cacheRead: 1.0, cacheWrite: 8.0 },
  },
  {
    id: "gemini/gemini-2.5-flash",
    name: "Gemini 2.5 Flash",
    reasoning: false,
    input: ["text", "image"],
    contextWindow: 1048576,
    maxTokens: 65536,
    cost: { input: 0.24, output: 2.0, cacheRead: 0.24, cacheWrite: 2.0 },
  },
  {
    id: "gemini/gemini-2.5-flash-lite",
    name: "Gemini 2.5 Flash Lite",
    reasoning: false,
    input: ["text", "image"],
    contextWindow: 1048576,
    maxTokens: 65536,
    cost: { input: 0.08, output: 0.32, cacheRead: 0.08, cacheWrite: 0.32 },
  },
  {
    id: "x-ai/grok-4-fast",
    name: "Grok 4 Fast",
    reasoning: false,
    input: ["text", "image"],
    contextWindow: 2000000,
    maxTokens: 32768,
    cost: { input: 0.2, output: 0.5, cacheRead: 0.2, cacheWrite: 0.5 },
  },

  // --- Reasoning models ---
  {
    id: "zai-org/GLM-5",
    name: "GLM 5",
    reasoning: true,
    input: ["text"],
    contextWindow: 202752,
    maxTokens: 32768,
    cost: { input: 0.8, output: 2.56, cacheRead: 0.8, cacheWrite: 2.56 },
  },
  {
    id: "zai-org/GLM-4.7",
    name: "GLM 4.7",
    reasoning: true,
    input: ["text"],
    contextWindow: 202752,
    maxTokens: 8192,
    cost: { input: 0.2, output: 0.8, cacheRead: 0.2, cacheWrite: 0.8 },
  },
  {
    id: "zai-org/GLM-4.6",
    name: "GLM 4.6",
    reasoning: true,
    input: ["text"],
    contextWindow: 202752,
    maxTokens: 8192,
    cost: { input: 0.45, output: 1.9, cacheRead: 0.45, cacheWrite: 1.9 },
  },
  {
    id: "deepseek-ai/DeepSeek-R1-0528",
    name: "DeepSeek R1 0528",
    reasoning: true,
    input: ["text"],
    contextWindow: 163840,
    maxTokens: 32768,
    cost: { input: 0.5, output: 2.15, cacheRead: 0.5, cacheWrite: 2.15 },
  },
  {
    id: "deepseek-ai/DeepSeek-V3.1",
    name: "DeepSeek V3.1",
    reasoning: true,
    input: ["text"],
    contextWindow: 163840,
    maxTokens: 8192,
    cost: { input: 0.27, output: 1.0, cacheRead: 0.27, cacheWrite: 1.0 },
  },
  {
    id: "moonshotai/Kimi-K2-Thinking",
    name: "Kimi K2 Thinking",
    reasoning: true,
    input: ["text"],
    contextWindow: 262144,
    maxTokens: 32768,
    cost: { input: 0.6, output: 2.6, cacheRead: 0.6, cacheWrite: 2.6 },
  },

  // --- Open-source / general models ---
  {
    id: "deepseek-ai/DeepSeek-V3.2",
    name: "DeepSeek V3.2",
    reasoning: false,
    input: ["text"],
    contextWindow: 163840,
    maxTokens: 8192,
    cost: { input: 0.26, output: 0.38, cacheRead: 0.26, cacheWrite: 0.38 },
  },
  {
    id: "deepseek-ai/DeepSeek-V3-0324",
    name: "DeepSeek V3 0324",
    reasoning: false,
    input: ["text"],
    contextWindow: 163840,
    maxTokens: 8192,
    cost: { input: 0.25, output: 0.88, cacheRead: 0.25, cacheWrite: 0.88 },
  },
  {
    id: "meta-llama/Llama-3.3-70B-Instruct",
    name: "Llama 3.3 70B Instruct",
    reasoning: false,
    input: ["text"],
    contextWindow: 131072,
    maxTokens: 10000,
    cost: { input: 0.1, output: 0.3, cacheRead: 0.1, cacheWrite: 0.3 },
  },
  {
    id: "Qwen/Qwen3-235B-A22B-Instruct-2507",
    name: "Qwen3 235B A22B Instruct",
    reasoning: false,
    input: ["text"],
    contextWindow: 262144,
    maxTokens: 32768,
    cost: { input: 0.09, output: 0.57, cacheRead: 0.09, cacheWrite: 0.57 },
  },
  {
    id: "moonshotai/Kimi-K2.5",
    name: "Kimi K2.5",
    reasoning: false,
    input: ["text", "image"],
    contextWindow: 262144,
    maxTokens: 32768,
    cost: { input: 0.45, output: 2.8, cacheRead: 0.45, cacheWrite: 2.8 },
  },
  {
    id: "MiniMaxAI/MiniMax-M2.1",
    name: "MiniMax M2.1",
    reasoning: false,
    input: ["text"],
    contextWindow: 196608,
    maxTokens: 8192,
    cost: { input: 0.28, output: 1.2, cacheRead: 0.28, cacheWrite: 1.2 },
  },
  {
    id: "MiniMaxAI/MiniMax-M2.5",
    name: "MiniMax M2.5",
    reasoning: false,
    input: ["text"],
    contextWindow: 204800,
    maxTokens: 8192,
    cost: { input: 0.3, output: 1.2, cacheRead: 0.3, cacheWrite: 1.2 },
  },
  {
    id: "XiaomiMiMo/MiMo-V2-Flash",
    name: "MiMo V2 Flash",
    reasoning: false,
    input: ["text"],
    contextWindow: 262144,
    maxTokens: 8192,
    cost: { input: 0.1, output: 0.3, cacheRead: 0.1, cacheWrite: 0.3 },
  },
  {
    id: "mistralai/Mistral-Nemo-Instruct-2407",
    name: "Mistral Nemo Instruct",
    reasoning: false,
    input: ["text"],
    contextWindow: 131072,
    maxTokens: 8192,
    cost: { input: 0.02, output: 0.04, cacheRead: 0.02, cacheWrite: 0.04 },
  },
];

export function buildMeganovaModelDefinition(
  model: (typeof MEGANOVA_MODEL_CATALOG)[number],
): ModelDefinitionConfig {
  return {
    id: model.id,
    name: model.name,
    api: "openai-completions",
    reasoning: model.reasoning,
    input: model.input,
    cost: model.cost,
    contextWindow: model.contextWindow,
    maxTokens: model.maxTokens,
    compat: {
      supportsReasoningEffort: false,
    },
  };
}
